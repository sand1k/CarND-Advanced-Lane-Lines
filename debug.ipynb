{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a distortion correction to raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Define named constants for debug and ndebug modes\n",
    "DBG = True\n",
    "NO_DBG = False\n",
    "\n",
    "# Define global constants corresponding to image dimensions\n",
    "img = cv2.imread('camera_cal/calibration1.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "G_SHAPE = img.shape\n",
    "G_W = G_SHAPE[1]\n",
    "G_H = G_SHAPE[0]\n",
    "\n",
    "#\n",
    "# Find coners on chessboard images and prepare points for calibrateCamera\n",
    "#\n",
    "CB_X = 6\n",
    "CB_Y = 9\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((CB_X * CB_Y, 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0 : CB_Y, 0 : CB_X].T.reshape(-1, 2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    chess_img = cv2.imread(fname)\n",
    "    chess_img_gray = cv2.cvtColor(chess_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(chess_img_gray, (CB_Y, CB_X), None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "#\n",
    "# Find camera calibration parameters given object points and image points\n",
    "#\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "#\n",
    "# Helper function to undistort images\n",
    "#\n",
    "def undistort(img):\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return dst\n",
    "\n",
    "\n",
    "dst = undistort(img)\n",
    "dst = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use color transforms, gradients, etc., to create a thresholded binary image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "fname = 'test_images/straight_lines2.jpg'\n",
    "img = mpimg.imread(fname) \n",
    "\n",
    "clip_names = [\"project_video.mp4\",\n",
    "              \"challenge_video.mp4\",\n",
    "              \"harder_challenge_video.mp4\"]\n",
    "\n",
    "#frame_num = 664\n",
    "#clip1 = VideoFileClip(clip_names[2])\n",
    "#img = clip1.get_frame(float(frame_num)/clip1.fps)\n",
    "#clip1.close()\n",
    "\n",
    "\n",
    "# Define a function that thresholds the S-channel of HLS\n",
    "# Use exclusive lower bound (>) and inclusive upper (<=)\n",
    "def hls_select(channel, thresh=(0, 255), ch='s'):\n",
    "    # 1) Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    # 2) Apply a threshold to the S channel\n",
    "    channel = 0\n",
    "    if ch == 'h':\n",
    "        channel = hls[:,:,0]\n",
    "    elif ch == 'l':\n",
    "        channel = hls[:,:,1]\n",
    "    else:\n",
    "        channel = hls[:,:,2]\n",
    "    \n",
    "    binary = np.zeros_like(channel)\n",
    "    binary[(channel > thresh[0]) & (channel <= thresh[1])] = 1\n",
    "    # 3) Return a binary image of threshold result\n",
    "    return binary\n",
    "\n",
    "def channel_select(channel, thresh=(0, 255)):\n",
    "    binary = np.zeros_like(channel)\n",
    "    binary[(channel > thresh[0]) & (channel <= thresh[1])] = 1\n",
    "    # 3) Return a binary image of threshold result\n",
    "    return binary\n",
    "\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "    \n",
    "hls_binary = hls_select(img, thresh=(90, 255))\n",
    "\n",
    "# Plot different channels\n",
    "G_CLACHE = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "G_CLACHE_STR = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8, 8))\n",
    "hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "yuv = cv2.cvtColor(img, cv2.COLOR_RGB2YUV);\n",
    "\n",
    "y_channel = yuv[:,:,0]\n",
    "u_channel = yuv[:,:,1]\n",
    "v_channel = yuv[:,:,2]\n",
    "\n",
    "# equalize the histogram of the Y channel\n",
    "#yuv[:,:,0] = cv2.equalizeHist(yuv[:,:,0])\n",
    "y_norm = cv2.equalizeHist(yuv[:,:,0])\n",
    "# convert the YUV image back to RGB format\n",
    "img_norm = cv2.cvtColor(yuv, cv2.COLOR_YUV2RGB)\n",
    "\n",
    "h_channel = hls[:,:,0]\n",
    "l_channel = hls[:,:,1]\n",
    "s_channel = hls[:,:,2]\n",
    "\n",
    "r_channel = img[:,:,0]\n",
    "g_channel = img[:,:,1]\n",
    "b_channel = img[:,:,2]\n",
    "\n",
    "\n",
    "r_cl = G_CLACHE.apply(r_channel)\n",
    "g_cl = G_CLACHE.apply(g_channel)\n",
    "s_cl = G_CLACHE.apply(s_channel)\n",
    "\n",
    "wl = np.uint8(r_channel*0.299 + g_channel*0.587 + b_channel*0.1170)\n",
    "wl_cl = G_CLACHE.apply(wl)\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "cl = G_CLACHE.apply(gray)\n",
    "\n",
    "#f, (ax) = plt.subplots(3, 2, figsize=(15, 15))\n",
    "#ax[0, 0].imshow(h_channel, cmap='gray')\n",
    "#ax[0, 0].set_title('H channel', fontsize=50)\n",
    "#ax[0, 1].imshow(l_channel, cmap='gray')\n",
    "#ax[0, 1].set_title('L channel', fontsize=50)\n",
    "#ax[1, 0].imshow(s_channel, cmap='gray')\n",
    "#ax[1, 0].set_title('S channel', fontsize=50)\n",
    "#ax[1, 1].imshow(r_channel, cmap='gray')\n",
    "#ax[1, 1].set_title('R channel', fontsize=50)\n",
    "#ax[2, 0].imshow(g_channel, cmap='gray')\n",
    "#ax[2, 0].set_title('G channel', fontsize=50)\n",
    "#ax[2, 1].imshow(b_channel, cmap='gray')\n",
    "#ax[2, 1].set_title('B channel', fontsize=50)\n",
    "\n",
    "f, (ax) = plt.subplots(5, 2, figsize=(10, 15))\n",
    "ax[0, 0].imshow(r_channel, cmap='gray')\n",
    "ax[0, 0].set_title('R channel', fontsize=20)\n",
    "ax[0, 1].imshow(r_cl, cmap='gray')\n",
    "ax[0, 1].set_title('R clache', fontsize=20)\n",
    "ax[1, 0].imshow(wl, cmap='gray')\n",
    "ax[1, 0].set_title('W3C lightness', fontsize=20)\n",
    "ax[1, 1].imshow(s_channel, cmap='gray')\n",
    "ax[1, 1].set_title('S channel', fontsize=20)\n",
    "\n",
    "ax[2, 0].imshow(l_channel, cmap='gray')\n",
    "ax[2, 0].set_title('L channel', fontsize=20)\n",
    "ax[2, 1].imshow(s_channel, cmap='gray')\n",
    "ax[2, 1].set_title('S clache', fontsize=20)\n",
    "ax[3, 0].imshow(gray, cmap='gray')\n",
    "ax[3, 0].set_title('Gray', fontsize=20)\n",
    "ax[3, 1].imshow(cl, cmap='gray')\n",
    "ax[3, 1].set_title('Gray clache', fontsize=20)\n",
    "ax[4, 0].imshow(y_channel, cmap='gray')\n",
    "ax[4, 0].set_title('Y', fontsize=20)\n",
    "ax[4, 1].imshow(yuv[:,:,0], cmap='gray')\n",
    "ax[4, 1].set_title('Y norm', fontsize=20)\n",
    "\n",
    "\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', thresh=(0, 255)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel > thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def abs_sobel_thresh_hls(img, orient='x', thresh=(0, 255)):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)[:,:,2]\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(hls, cv2.CV_64F, 1, 0)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(hls, cv2.CV_64F, 0, 1)\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel > thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def abs_raw_sobel(channel, orient='x', thresh=(30, 255)):\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(channel, cv2.CV_64F, 1, 0)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(channel, cv2.CV_64F, 0, 1)\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel > thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def mag_thresh(gray, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    #gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    mag = np.sqrt(np.square(sobelx) + np.square(sobely))\n",
    "    scaled_mag = np.uint8(255*mag/np.max(mag))\n",
    "    binary_output = np.zeros_like(scaled_mag)\n",
    "    binary_output[(scaled_mag >= mag_thresh[0]) & (scaled_mag <= mag_thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def dir_thresh(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    abs_sobelx = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    abs_sobely = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "    dir = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    binary_output = np.zeros_like(dir, dtype=np.uint8)\n",
    "    binary_output[(dir >= thresh[0]) & (dir <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "    \n",
    "# Run the function\n",
    "x_sobel = abs_raw_sobel(cl, 'x', (15, 255))\n",
    "y_sobel = abs_raw_sobel(cl, 'y', (15, 255))\n",
    "mag_sobel = mag_thresh(cl, 5, (15, 255))\n",
    "dir_sobel = dir_thresh(img, sobel_kernel=15, thresh=(0.95, 1.05)) #thresh=(0.7, 1.3))\n",
    "sobel_S = abs_raw_sobel(s_channel, 'x', (20, 255))\n",
    "x_sobel_R = abs_raw_sobel(r_cl, 'x', (20, 255))\n",
    "sobel_Y = abs_raw_sobel(y_norm, 'x', (10, 255))\n",
    "cny = canny(img, 50, 150)\n",
    "\n",
    "# Plot the result\n",
    "f, ax = plt.subplots(4, 2, figsize=(15, 20))\n",
    "ax[0, 0].imshow(x_sobel, cmap='gray')\n",
    "ax[0, 0].set_title('X sobel', fontsize=30)\n",
    "ax[0, 1].imshow(y_sobel, cmap='gray')\n",
    "ax[0, 1].set_title('Y sobel', fontsize=30)\n",
    "ax[1, 0].imshow(mag_sobel, cmap='gray')\n",
    "ax[1, 0].set_title('Mag sobel', fontsize=30)\n",
    "ax[1, 1].imshow(dir_sobel, cmap='gray')\n",
    "ax[1, 1].set_title('Dir sobel', fontsize=30)\n",
    "ax[2, 0].imshow(sobel_S, cmap='gray')\n",
    "ax[2, 0].set_title('Sobel S', fontsize=30)\n",
    "ax[2, 1].imshow(x_sobel_R, cmap='gray')\n",
    "ax[2, 1].set_title('Sobel R', fontsize=30)\n",
    "ax[3, 0].imshow(sobel_Y, cmap='gray')\n",
    "ax[3, 0].set_title('Sobel Y', fontsize=20)\n",
    "\n",
    "\n",
    "#f.tight_layout()\n",
    "#ax1.imshow(image)\n",
    "#ax1.set_title('Original Image', fontsize=50)\n",
    "#ax2.imshow(mag_binary, cmap='gray')\n",
    "#ax2.set_title('Thresholded Image', fontsize=50)\n",
    "#plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import progressbar\n",
    "\n",
    "undist = undistort(img)\n",
    "\n",
    "   \n",
    "def make_binary(img):\n",
    "    img = np.copy(img)\n",
    "    \n",
    "    den = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7,21)\n",
    "    #den = cv2.bilateralFilter(img, 9, 75, 75)\n",
    "    #denoised = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7,21)\n",
    "    # \n",
    "    # Prepare masks\n",
    "    #\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    den_gray = cv2.cvtColor(den, cv2.COLOR_RGB2GRAY)\n",
    "    R_channel = img[:,:,0]\n",
    "    G_channel = img[:,:,1]\n",
    "    B_channel = img[:,:,2]\n",
    "    \n",
    "    #H_channel = hls[:,:,0]\n",
    "    #L_channel = hls[:,:,1]\n",
    "    S_channel = hls[:,:,2]\n",
    "    \n",
    "    wl = np.uint8(R_channel*0.299 + G_channel*0.587 + B_channel*0.1170)\n",
    "    \n",
    "    gray_cl = G_CLACHE.apply(gray)\n",
    "    den_gray_cl = G_CLACHE.apply(den_gray)\n",
    "    #den_gray_cl_den = cv.fastNlMeansDenoisingMulti(noisy, 2, 5, None, 4, 7, 35)\n",
    "    R_channel_cl = G_CLACHE.apply(R_channel)\n",
    "    G_channel_cl = G_CLACHE.apply(G_channel)\n",
    "    B_channel_cl = G_CLACHE.apply(B_channel)\n",
    "    R_channel_den = den[:,:,0]\n",
    "    G_channel_den = den[:,:,1]\n",
    "    B_channel_den = den[:,:,2]\n",
    "\n",
    "    # Gray mask\n",
    "    gray_reg = np.zeros_like(gray)\n",
    "    diff_RG = abs(np.int32(R_channel_den) - np.int32(G_channel_den))\n",
    "    diff_GB = abs(np.int32(G_channel_den) - np.int32(B_channel_den))\n",
    "    diff_RB = abs(np.int32(R_channel_den) - np.int32(B_channel_den))\n",
    "    gray_reg[(diff_RG <= 25) & (diff_GB <= 25) & (diff_RB <= 25)] = 1\n",
    "    gray_reg_er = cv2.erode(gray_reg, np.ones((5,5)), iterations = 2)\n",
    "    \n",
    "    # Gray mask + white lanes\n",
    "    white_mask = channel_select(gray, (180, 255))\n",
    "    white_mask = cv2.dilate(white_mask, np.ones((5,5)), iterations = 1)\n",
    "    gray_and_white_reg = np.copy(gray_reg)\n",
    "    gray_and_white_reg[(white_mask == 1)] = 0\n",
    "    \n",
    "    # Colored mask\n",
    "    color_reg = np.zeros_like(den_gray)\n",
    "    color_reg[(diff_RG > 15) | (diff_GB > 15) | (diff_RB > 15)] = 1\n",
    "    color_reg_cl = cv2.dilate(color_reg, np.ones((5,5)), iterations = 1)\n",
    "    color_reg_er = cv2.erode(color_reg, np.ones((5,5)), iterations = 2)\n",
    "     \n",
    "    # Dark blue mask\n",
    "    dark_blue_reg = np.zeros_like(gray)\n",
    "    diff1 = (np.int32(B_channel) - np.int32(G_channel))\n",
    "    diff2 = (np.int32(B_channel) - np.int32(R_channel))\n",
    "    dark_blue_reg[(diff1 > 10) & (diff2 > 10)] = 1\n",
    "    dark_blue_reg[(den_gray >= 80)] = 0\n",
    "    dark_blue_reg_dl = cv2.dilate(dark_blue_reg, np.ones((5,5)), iterations = 1)\n",
    "    dark_blue_reg_er = cv2.erode(dark_blue_reg, np.ones((5,5)), iterations = 2)\n",
    "    \n",
    "    # Dark mask\n",
    "    dark_reg = np.zeros_like(gray)\n",
    "    \n",
    "    #\n",
    "    # Do thresholding\n",
    "    #\n",
    "    \n",
    "    # 1. Threshold HLS\n",
    "    S_sobel = abs_raw_sobel(S_channel, 'x', (30, 255))\n",
    "    HLS_binary = S_sobel\n",
    "    HLS_binary[(color_reg_er == 1)] = 0\n",
    "    HLS_binary[(gray_reg_er == 1)] = 0\n",
    "    \n",
    "    \n",
    "    # 2. Threshold based on sobel edge detection\n",
    "    sobel_x = abs_raw_sobel(den_gray_cl, 'x', (30, 255))\n",
    "    sobel_x[(gray_and_white_reg == 1)] = 0\n",
    "    \n",
    "    sobel_strong = abs_raw_sobel(den_gray_cl, 'x', (15, 255))\n",
    "    wl_mask = channel_select(wl, (100, 255))\n",
    "    wl_mask_dl = cv2.dilate(wl_mask, np.ones((5,5)), iterations = 1)\n",
    "    high_S = channel_select(S_channel, (40, 255))\n",
    "    high_S_dl = cv2.dilate(high_S, np.ones((5,5)), iterations = 1)\n",
    "    sobel_dark = np.copy(sobel_strong)\n",
    "    sobel_dark[wl_mask_dl == 1] = 0\n",
    "    #sobel_dark[high_S_dl == 0] = 0\n",
    "    \n",
    "    sobel_dark_blue = np.copy(dark_blue_reg_dl)\n",
    "    sobel_dark_blue[(sobel_strong == 0)] = 0\n",
    "    sobel_dark_blue[(high_S_dl == 0)] = 0\n",
    "       \n",
    "    sobel = sobel_dark #sobel_x #| sobel_dark | sobel_dark_blue    \n",
    "            \n",
    "    # 3. Color threshold\n",
    "    RGB_binary = np.zeros_like(gray_cl)\n",
    "    \n",
    "    # Yellow filter\n",
    "    # (Good detection of yellow lane on challenge video)\n",
    "    R_filtered = channel_select(R_channel_cl, (160, 255))\n",
    "    G_filtered = channel_select(G_channel_cl, (160, 255))\n",
    "    B_filtered = channel_select(B_channel_cl, (0, 130))\n",
    "    RGB_binary[(R_filtered == 1) & (G_filtered == 1) & (B_filtered == 1)] = 1\n",
    "    \n",
    "    # White filter      \n",
    "    white_sel = channel_select(gray_cl, (210, 255))\n",
    "    L_filtered = channel_select(wl, (0, 150))\n",
    "    L_dilated = cv2.dilate(L_filtered, np.ones((5,5)), iterations = 1)\n",
    "    white_sel[(L_dilated != 1)] = 0\n",
    "       \n",
    "    sobel_light = abs_raw_sobel(wl, 'x', (25, 255))\n",
    "    L_filtered = channel_select(wl, (0, 120))\n",
    "    L_dilated = cv2.dilate(L_filtered, np.ones((5,5)), iterations = 1)\n",
    "    sobel_light[(L_dilated == 1)] = 0\n",
    "    RGB_binary[(white_sel == 1) | (sobel_light == 1)] = 1\n",
    "    RGB_binary[(color_reg_er == 1)] = 0\n",
    "\n",
    "    #\n",
    "    # Output\n",
    "    #\n",
    "    dbg = np.dstack((dark_blue_reg, dark_blue_reg, dark_blue_reg)) * 255\n",
    "    #dbg2 = np.dstack((wl, wl, wl)) * 255\n",
    "    color_binary = np.dstack((HLS_binary, sobel, RGB_binary)) * 255\n",
    "    color_binary = np.concatenate((den, color_binary), axis = 1)\n",
    "    \n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sobel)\n",
    "    combined_binary[(HLS_binary == 1) | (sobel == 1) | (RGB_binary == 1)] = 1\n",
    "    return (combined_binary, color_binary)\n",
    "    \n",
    "(comb_bin, col_bin) = make_binary(undist)\n",
    "\n",
    "# Plot the result\n",
    "#f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "#f, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 25))\n",
    "\n",
    "#ax1.imshow(img)\n",
    "#ax1.set_title('Original Image', fontsize=20)\n",
    "\n",
    "#ax2.imshow(col_bin)\n",
    "#ax2.set_title('Pipeline Result', fontsize=20)\n",
    "\n",
    "#ax3.imshow(comb_bin, cmap='gray')\n",
    "#ax3.set_title('Combined binary', fontsize=20)\n",
    "\n",
    "#base = os.path.splitext(os.path.basename(fname))[0]\n",
    "#mpimg.imsave('output_dbg/dbg_' + base + '.png', res)\n",
    "\n",
    "# vid1 548;\n",
    "# vid2 80 - 4 lanes\n",
    "#      131 - tunnel\n",
    "#      152 - after tunnel\n",
    "frames = [[548],\n",
    "          [0, 12, 29, 80, 125, 131, 145, 152, 157, 263, 451],\n",
    "          [0, 175, 185, 281, 284, 310, 337, 338, 344, 580, 664]]\n",
    "\n",
    "for idx, clip_name in enumerate(clip_names):\n",
    "    clip1 = VideoFileClip(clip_name)\n",
    "\n",
    "    for frame_num in progressbar.log_progress(frames[idx], every=1):\n",
    "        timg = clip1.get_frame(float(frame_num)/clip1.fps)\n",
    "        und = undistort(timg)\n",
    "        (binary, dbg) = make_binary(und)\n",
    "        dbg = np.concatenate((und, dbg), axis=1)\n",
    "        mpimg.imsave('output_dbg2/a_vid' + str(idx) + '_dbg_' + str(frame_num) + '.png', dbg)\n",
    "        \n",
    "    clip1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a perspective transform to rectify binary image (\"birds-eye view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_persp_matr(src_corners, dst_corners):\n",
    "    src = np.float32(src_corners)\n",
    "    dst = np.float32(dst_corners)\n",
    "    m = cv2.getPerspectiveTransform(src, dst)\n",
    "    m_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "    return m, m_inv\n",
    "\n",
    "G_SRC_CORNERS = [[240, G_H], # left bottom\n",
    "                 [620, 460], # left top\n",
    "                 [730, 460], # right top\n",
    "                 [1160, G_H]] # right bottom\n",
    "\n",
    "#G_SRC_CORNERS = np.array([np.array([LMARGIN, G_H]), # left bottom\n",
    "#                          np.array([HMARGIN, Y_EDGE]), # left top\n",
    "#                          np.array([G_W - HMARGIN, Y_EDGE]), # right top\n",
    "#                          np.array([G_W - LMARGIN, G_H])]) # right bottom\n",
    "           \n",
    "G_DST_CORNERS = [[280, G_H],\n",
    "                 [280, 0],\n",
    "                 [1000, 0],\n",
    "                 [1000, G_H]]\n",
    "\n",
    "G_M, G_M_inv = calc_persp_matr(G_SRC_CORNERS, G_DST_CORNERS)\n",
    "\n",
    "def perspective_transform(img, M, debug = False):  \n",
    "    warped = cv2.warpPerspective(img,\n",
    "                                 M,\n",
    "                                 (img.shape[1], img.shape[0]),\n",
    "                                 flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warped\n",
    "\n",
    "warped = perspective_transform(comb_bin, G_M)\n",
    "\n",
    "# Plot the result\n",
    "colored_comb_bin = np.dstack((comb_bin, comb_bin, comb_bin)) * 255\n",
    "cv2.polylines(colored_comb_bin,\n",
    "              [np.array(G_SRC_CORNERS,dtype=np.int32).reshape((-1, 1, 2))],\n",
    "              True,\n",
    "              (255,255,0),\n",
    "              thickness = 2)\n",
    "\n",
    "colored_warped = np.dstack((warped, warped, warped)) * 255\n",
    "cv2.polylines(colored_warped,\n",
    "              [np.array(G_DST_CORNERS, dtype=np.int32).reshape((-1, 1, 2))],\n",
    "              True,\n",
    "              (255,255,0),\n",
    "              thickness=2)\n",
    "\n",
    "#f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "f.tight_layout()\n",
    "\n",
    "ax1.imshow(colored_comb_bin)\n",
    "ax1.set_title('Binary', fontsize=40)\n",
    "\n",
    "ax2.imshow(colored_warped)\n",
    "ax2.set_title('Warped', fontsize=40)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect lane pixels and fit to find the lane boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_pixels(binary_warped, vis):\n",
    "    # Visualisation\n",
    "    out_img = None\n",
    "    if vis:\n",
    "        out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "        \n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 150\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    left_off = 0\n",
    "    right_off = 0\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        \n",
    "        ##Find the four below boundaries of the window\n",
    "        win_xleft_low = leftx_current  - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        if vis:\n",
    "            cv2.rectangle(out_img, (win_xleft_low, win_y_low), (win_xleft_high, win_y_high),\n",
    "                          (0, 255, 0), 2) \n",
    "            cv2.rectangle(out_img, (win_xright_low, win_y_low), (win_xright_high, win_y_high),\n",
    "                          (0, 255, 0), 2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        \n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If found > minpix pixels, recenter next window\n",
    "        # (`right` or `leftx_current`) on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_mean = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            leftx_current = leftx_mean\n",
    "            \n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_mean = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "            rightx_current = rightx_mean\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "def fit_polynomial(binary_warped, vis):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped, vis)\n",
    "\n",
    "    # Fit a second order polynomial to each using `np.polyfit` ###\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    if vis:\n",
    "        # Colorize alne pixels\n",
    "        out_img[lefty, leftx] = [255, 0, 0]\n",
    "        out_img[righty, rightx] = [0, 0, 255]\n",
    "        \n",
    "        # Draw polynom approximation\n",
    "        cv2.polylines(out_img,\n",
    "                      [np.array([left_fitx, ploty], dtype=np.int32).T],\n",
    "                      False,\n",
    "                      (255,255,0),\n",
    "                      thickness=2)\n",
    "        cv2.polylines(out_img,\n",
    "                      [np.array([right_fitx, ploty], dtype=np.int32).T],\n",
    "                      False,\n",
    "                      (255,255,0),\n",
    "                      thickness=2)\n",
    "        \n",
    "\n",
    "    return ploty, left_fit, right_fit, left_fitx, right_fitx, out_img\n",
    "\n",
    "py, lf, rf, lfx, rfx, vis = fit_polynomial(warped, True)\n",
    "\n",
    "# Plots the left and right polynomials on the lane lines\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find perspective rectangle with desired top edge width based on linear approximation of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# line segment intersection using vectors\n",
    "# see Computer Graphics by F.S. Hill\n",
    "#\n",
    "def perp( a ) :\n",
    "    b = np.empty_like(a)\n",
    "    b[0] = -a[1]\n",
    "    b[1] = a[0]\n",
    "    return b\n",
    "\n",
    "# line segment a given by endpoints a1, a2\n",
    "# line segment b given by endpoints b1, b2\n",
    "# return \n",
    "def seg_intersect(a1,a2, b1,b2):\n",
    "    da = a2-a1\n",
    "    db = b2-b1\n",
    "    dp = a1-b1\n",
    "    dap = perp(da)\n",
    "    denom = np.dot( dap, db)\n",
    "    num = np.dot( dap, dp )\n",
    "    return (num / denom.astype(float))*db + b1\n",
    "\n",
    "# find k, b for x = ky + b\n",
    "def fit_line(x_dots, y_dots):\n",
    "    A = np.vstack([y_dots, np.ones(len(y_dots))]).T     \n",
    "    k, b = np.linalg.lstsq(A, x_dots)[0]\n",
    "    return (k, b)\n",
    "\n",
    "def find_linear_lines(left_dots, right_dots, dbg_img):\n",
    "    left_x = np.array(left_dots[0].T[0])\n",
    "    left_y = np.array(left_dots[0].T[1])\n",
    "    right_x = np.array(right_dots[0].T[0])\n",
    "    right_y = np.array(right_dots[0].T[1])\n",
    "\n",
    "    selected_left = ((left_x >=0) & (left_x <= G_W - 1) & (left_y >= 550)).nonzero()[0]\n",
    "    selected_right = ((right_x >=0) & (right_x <= G_W - 1) & (right_y >= 550)).nonzero()[0]\n",
    "\n",
    "    (lk, lb) = fit_line(left_x[selected_left], left_y[selected_left])\n",
    "    (rk, rb) = fit_line(right_x[selected_right], right_y[selected_right])\n",
    "    \n",
    "    if dbg_img is not None:        \n",
    "        dbg_img[left_y[selected_left], left_x[selected_left]] = [255, 0, 0]\n",
    "        dbg_img[right_y[selected_right], right_x[selected_right]] = [0, 0, 255]\n",
    "        \n",
    "        y_top, y_bot = 0, 720\n",
    "        cv2.line(dbg_img, (int(lk * y_bot + lb), y_bot), (int(lk * y_top + lb), y_top), [0, 255, 255], 2)\n",
    "        cv2.line(dbg_img, (int(rk * y_bot + rb), y_bot), (int(rk * y_top + rb), y_top), [0, 255, 255], 2)\n",
    "    \n",
    "    return (lk, lb), (rk, rb)\n",
    "\n",
    "def find_persp_rectangle(l_line, r_line, rect_top_width, dbg_img = None):    \n",
    "    # find cross point\n",
    "    y_top, y_bot = 0, 720\n",
    "    lk, lb = l_line\n",
    "    rk, rb = r_line\n",
    "    lp1 = np.array([lk * y_bot + lb, y_bot])\n",
    "    lp2 = np.array([lk * y_top + lb, y_top])\n",
    "    rp1 = np.array([rk * y_bot + rb, y_bot])\n",
    "    rp2 = np.array([rk * y_top + rb, y_top])\n",
    "    \n",
    "    cp = seg_intersect(lp1, lp2, rp1, rp2)\n",
    "    rect_bot_width = rp1[0] - lp1[0]\n",
    "    H = y_bot - cp[1]\n",
    "    L = cp[0] - lp1[0]\n",
    "    R = rp1[0] - cp[0]\n",
    "\n",
    "    if (cp[0] >= 0 and cp[0] <= G_W\n",
    "        and lp1[0] >= 0 and lp1[0] <= G_W\n",
    "        and rp1[0] >= 0 and rp1[0] <= G_W\n",
    "        and rect_bot_width > 0 #and L > 0 and R > 0\n",
    "        and rect_top_width < rect_bot_width):\n",
    "        \n",
    "        rect_height =  H * rect_top_width / rect_bot_width\n",
    "        \n",
    "        rect = [lp1, np.array([cp[0] - L * rect_top_width / rect_bot_width, cp[1] + rect_height]),\n",
    "                np.array([cp[0] + R * rect_top_width / rect_bot_width, cp[1] + rect_height]), rp1]\n",
    "        \n",
    "        if dbg_img is not None:\n",
    "            cv2.polylines(dbg_img,\n",
    "                          [np.array(rect, dtype=np.int32).reshape((-1, 1, 2))],\n",
    "                          True, (255, 0, 0), thickness = 2)\n",
    "        \n",
    "        return rect\n",
    "           \n",
    "    return None\n",
    "\n",
    "py = np.linspace(0, G_H - 1, G_H)\n",
    "# Convert polynomial dots to original perspective\n",
    "left_dots = cv2.perspectiveTransform(np.array([np.array([lfx, py], dtype=np.float32).T]), G_M_inv).astype(int)\n",
    "right_dots = cv2.perspectiveTransform(np.array([np.array([rfx, py], dtype=np.float32).T]), G_M_inv).astype(int)\n",
    "\n",
    "# find linear approximations of lines\n",
    "pic1 = np.dstack((comb_bin, comb_bin, comb_bin))*255\n",
    "left_l, right_l = find_linear_lines(left_dots, right_dots, pic1)\n",
    "\n",
    "pic2 = colored_comb_bin\n",
    "new_corners = find_persp_rectangle(left_l, right_l, 250, pic2)\n",
    "\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "f.tight_layout()\n",
    "ax1.imshow(pic1)\n",
    "ax1.set_title('Lines approximation', fontsize=40)\n",
    "\n",
    "ax2.imshow(pic2)\n",
    "ax2.set_title('New perspective rectangle', fontsize=40)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search from prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_poly(leftx, lefty, rightx, righty):\n",
    "    # Fit a second order polynomial to each with np.polyfit()\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    return left_fit, right_fit\n",
    "    \n",
    "def find_poly_values(left_fit, right_fit, img_shape):\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, G_H - 1, G_H)\n",
    "    # Calc both polynomials using ploty, left_fit and right_fit ###\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    return left_fitx, right_fitx, ploty\n",
    "\n",
    "def search_around_poly(binary_warped, left_fit, right_fit):\n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    # The quiz grader expects 100 here, but feel free to tune on your own!\n",
    "    margin = 70\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    ### Set the area of search based on activated x-values\n",
    "    ### within the +/- margin of our polynomial function\n",
    "    ### Hint: consider the window areas for the similarly named variables\n",
    "    ### in the previous quiz, but change the windows to our new search area\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    \n",
    "    min_found = 500\n",
    "    new_left_fit, new_right_fit = None, None\n",
    "    if len(leftx) < min_found or len(rightx) < min_found:\n",
    "        new_left_fit = left_fit\n",
    "        new_right_fit = right_fit\n",
    "        ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "        return ploty, new_left_fit, new_right_fit, None, None, out_img  \n",
    "    \n",
    "    # Fit new polynomials\n",
    "    new_left_fit, new_right_fit = fit_poly(leftx, lefty, rightx, righty)\n",
    "    \n",
    "    if (lefty < 360).sum() <= 10:\n",
    "        A = np.vstack([lefty, np.ones(len(lefty))]).T     \n",
    "        k, b = np.linalg.lstsq(A, leftx)[0]\n",
    "        new_left_fit[0] = 0\n",
    "        new_left_fit[1] = k\n",
    "        new_left_fit[2] = b\n",
    "        \n",
    "    if (righty < 360).sum() <= 10:\n",
    "        A = np.vstack([righty, np.ones(len(righty))]).T     \n",
    "        k, b = np.linalg.lstsq(A, rightx)[0]\n",
    "        new_right_fit[0] = 0\n",
    "        new_right_fit[1] = k\n",
    "        new_right_fit[2] = b\n",
    "    \n",
    "    left_fitx, right_fitx, ploty = find_poly_values(left_fit, right_fit,\n",
    "                                                    binary_warped.shape)\n",
    "    new_left_fitx, new_right_fitx, ploty = find_poly_values(new_left_fit, new_right_fit,\n",
    "                                                            binary_warped.shape)\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    cv2.polylines(out_img,\n",
    "                  [np.array([new_left_fitx, ploty], dtype=np.int32).T],\n",
    "                  False,\n",
    "                  (255,255,0),\n",
    "                  thickness=2)\n",
    "    cv2.polylines(out_img,\n",
    "                  [np.array([new_right_fitx, ploty], dtype=np.int32).T],\n",
    "                  False,\n",
    "                  (255,255,0),\n",
    "                  thickness=2)\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "       \n",
    "    return ploty, new_left_fit, new_right_fit, new_left_fitx, new_right_fitx, result\n",
    "\n",
    "# Run image through the pipeline\n",
    "# Note that in your project, you'll also want to feed in the previous fits\n",
    "py, lf, rf, lfx, rfx, vis2 = search_around_poly(warped, lf, rf)\n",
    "\n",
    "# View your output\n",
    "# Plot the polynomial lines onto the image\n",
    "plt.figure(figsize=(15, 15))\n",
    "#plt.plot(lfx, py, color='yellow')\n",
    "#plt.plot(rfx, py, color='yellow')\n",
    "## End visualization steps ##\n",
    "plt.imshow(vis2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the curvature of the lane and vehicle position with respect to center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature_real(ploty, left_fitx, right_fitx):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in pixels.\n",
    "    '''    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "    \n",
    "    # Do the calculation of R_curve (radius of curvature) \n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    pos = (img_size[0]/2 - (left_fitx[-1] + right_fitx[-1])/2) * xm_per_pix\n",
    "    \n",
    "\n",
    "    return left_curverad, right_curverad, pos\n",
    "\n",
    "# Calculate the radius of curvature in meters for both lane lines\n",
    "left_curverad, right_curverad, pos = measure_curvature_real(py, lfx, rfx)\n",
    "print(left_curverad, 'm', right_curverad, 'm', pos, 'm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warp the detected lane boundaries back onto the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lane(undist, warped, left_fitx, right_fitx, ploty, M_inv):\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, M_inv, (G_W, G_H)) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def draw_text(img, l_curverad, r_curverad, relative_pos,\n",
    "              is_found = None, left_fit = None, right_fit = None):\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    curve = ((l_curverad + r_curverad) / 2)\n",
    "    rad = '%.2f m' % curve if curve is not None else '-'\n",
    "    pos = '%.2f m' % relative_pos if relative_pos is not None else '-'\n",
    "    cv2.putText(img, 'Radius: ' + rad, (50, 50), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(img, 'Position: ' + pos, (50, 90), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    return img\n",
    "\n",
    "result = draw_lane(undist, warped, lfx, rfx, py, G_M_inv)\n",
    "result = draw_text(result, left_curverad, right_curverad, pos, '-', lf, rf)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import IntEnum\n",
    "\n",
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        self.detected = False  # was the line detected in the last iteration?\n",
    "        self.recent_xfitted = [] # x values of the last n fits of the line\n",
    "        self.recent_fit = [] # polynomial coefficients of the last n fits of the line\n",
    "        self.bestx = None #average x values of the fitted line over the last n iterations\n",
    "        self.best_fit = None #polynomial coefficients averaged over the last n iterations\n",
    "        self.current_fit = [np.array([False])] #polynomial coefficients for the most recent fit  \n",
    "        self.rad = None #radius of curvature of the line in some units\n",
    "        self.diffs = np.array([0,0,0], dtype='float') #difference in fit coefficients between last and new fits\n",
    "        self.allx = None #x values for detected line pixels\n",
    "        self.ally = None #y values for detected line pixels\n",
    "          \n",
    "class ProcessSeq:\n",
    "    WARPED_PIXELS_THRES = 110000\n",
    "    MAX_LOST_FRAMES = 5\n",
    "    HISTORY_SIZE = 6\n",
    "    MIN_FRAMES_TO_AVERAGE = 4\n",
    "    PERSP_RECT_TOP_MIN = 100\n",
    "    PERSP_RECT_TOP_MAX = 350\n",
    "    PERSP_RECT_TOP_DEF = 250\n",
    "    \n",
    "    def __init__(self, do_average = False, do_debug = False, def_corners = None, def_width = None):\n",
    "        self.l_lane = Line()\n",
    "        self.r_lane = Line()\n",
    "        self.frame = 0\n",
    "        self.lost_frames = self.MAX_LOST_FRAMES\n",
    "        self.lane_pos = 0\n",
    "        self.curv = 0\n",
    "        self.persp_rect_top = self.PERSP_RECT_TOP_DEF\n",
    "        if def_width is not None:\n",
    "            self.persp_rect_top = def_width\n",
    "        self.history_len = 0\n",
    "        self.warped_pixels = 0\n",
    "        self.do_average = do_average\n",
    "        self.do_debug = do_debug\n",
    "        lmargin, hmargin, yedge = 220, 515, 500\n",
    "        self.def_corners = [[lmargin, G_H], # left bottom\n",
    "                            [hmargin, yedge], # left top\n",
    "                            [G_W - hmargin, yedge], # right top\n",
    "                            [G_W - lmargin, G_H]] # right bottom\n",
    "        if def_corners is not None:\n",
    "            self.def_corners = def_corners\n",
    "        self.def_M, self.def_M_inv = calc_persp_matr(self.def_corners, G_DST_CORNERS)\n",
    "\n",
    "        self.corners = self.def_corners\n",
    "        self.M, self.M_inv = self.def_M, self.def_M_inv\n",
    "        \n",
    "        self.vis_bin = None\n",
    "    \n",
    "    def decrease_view_range(self):\n",
    "        self.persp_rect_top += 10\n",
    "        if self.persp_rect_top > self.PERSP_RECT_TOP_MAX:\n",
    "            self.persp_rect_top = self.PERSP_RECT_TOP_MAX\n",
    "            \n",
    "    def increase_view_range(self):\n",
    "        self.persp_rect_top -= 10\n",
    "        if self.persp_rect_top < self.PERSP_RECT_TOP_MIN:\n",
    "            self.persp_rect_top = self.PERSP_RECT_TOP_MIN\n",
    "    \n",
    "    def reset_view_range(self):\n",
    "        self.top_persp_rec = self.PERSP_RECT_TOP_DEF\n",
    "        \n",
    "    \n",
    "    def fit_dots(self, left_dots, right_dots):\n",
    "        leftx = left_dots[0].T[0]\n",
    "        lefty = left_dots[0].T[1]\n",
    "        rightx = right_dots[0].T[0]\n",
    "        righty = right_dots[0].T[1]\n",
    "\n",
    "        lf, rf = fit_poly(leftx, lefty, rightx, righty)\n",
    "        lfx, rfx, py = find_poly_values(lf, rf, G_SHAPE)\n",
    "        \n",
    "        return lf, rf, lfx, rfx\n",
    "    \n",
    "    def refit_lane(self, old_M_inv, new_M, lfx, rfx):\n",
    "        # Convert back to top view\n",
    "        py = np.linspace(0, G_H - 1, G_H)\n",
    "        left_dots = cv2.perspectiveTransform(np.array([np.array([lfx, py], dtype=np.float32).T]), old_M_inv)\n",
    "        right_dots = cv2.perspectiveTransform(np.array([np.array([rfx, py], dtype=np.float32).T]), old_M_inv)\n",
    "\n",
    "        # Convert to perspective view with new perspective transform\n",
    "        left_dots_p = cv2.perspectiveTransform(left_dots, new_M)\n",
    "        right_dots_p = cv2.perspectiveTransform(right_dots, new_M)\n",
    "\n",
    "        return self.fit_dots(left_dots_p, right_dots_p)\n",
    "    \n",
    "    def update_history(self, old_M_inv, new_M):\n",
    "        for idx in range(self.history_len):\n",
    "            lf, rf, lfx, rfx = self.refit_lane(old_M_inv, new_M,\n",
    "                                               self.l_lane.recent_xfitted[idx], self.r_lane.recent_xfitted[idx])\n",
    "            self.l_lane.recent_fit[idx], self.r_lane.recent_fit[idx] = lf, rf\n",
    "            self.l_lane.recent_xfitted[idx], self.r_lane.recent_xfitted[idx] = lfx, rfx\n",
    "        \n",
    "    def update_perspective(self, lf, rf, lfx, rfx):\n",
    "        # Translate lines coordinates to original image\n",
    "        py = np.linspace(0, G_H - 1, G_H)\n",
    "        left_dots = cv2.perspectiveTransform(np.array([np.array([lfx, py], dtype=np.float32).T]), self.M_inv)\n",
    "        right_dots = cv2.perspectiveTransform(np.array([np.array([rfx, py], dtype=np.float32).T]), self.M_inv)\n",
    "               \n",
    "        # Find linear lines approximation\n",
    "        l_line, r_line = find_linear_lines(left_dots, right_dots, self.vis_bin)\n",
    "        \n",
    "        # Calculate new perspective matrix \n",
    "        corners = find_persp_rectangle(l_line, r_line, self.persp_rect_top)\n",
    "        \n",
    "        new_M, new_M_inv = None, None\n",
    "        if corners:\n",
    "            new_M, new_M_inv = calc_persp_matr(corners, G_DST_CORNERS)\n",
    "        \n",
    "        if corners is not None and new_M is not None:           \n",
    "            # Update current fit\n",
    "            left_dots_p = cv2.perspectiveTransform(left_dots, new_M)\n",
    "            right_dots_p = cv2.perspectiveTransform(right_dots, new_M)\n",
    "            lf, rf, lfx, rfx = self.fit_dots(left_dots_p, right_dots_p)\n",
    "            \n",
    "            if not self.is_good_lane(lf, rf, lfx, rfx):\n",
    "                return False, lf, rf, lfx, rfx\n",
    "            \n",
    "            if self.do_debug:\n",
    "                cv2.polylines(self.vis_bin,\n",
    "                              [np.array(corners, dtype=np.int32).reshape((-1, 1, 2))],\n",
    "                              True,\n",
    "                              (255,0,0),\n",
    "                              thickness=2)\n",
    "                \n",
    "            # Update history (as previos fits became invalid)\n",
    "            self.update_history(self.M_inv, new_M)\n",
    "\n",
    "            # Remember new perspective transform matrix\n",
    "            self.M = new_M\n",
    "            self.M_inv = new_M_inv\n",
    "            self.corners = corners\n",
    "    \n",
    "        return True, lf, rf, lfx, rfx \n",
    "        \n",
    "    def is_good_lane(self, left_fit, right_fit, left_fitx, right_fitx):\n",
    "        if left_fitx is None:\n",
    "            return False\n",
    "        \n",
    "        # If lane cuvature changed too agressively, detection is incorrect\n",
    "        if self.history_len > 0:\n",
    "            l_diff = abs(left_fit - self.l_lane.recent_fit[-1])\n",
    "            r_diff = abs(right_fit - self.r_lane.recent_fit[-1])\n",
    "            if (l_diff[0] > 5.0e-04 or r_diff[0] > 5.0e-04):\n",
    "                return False\n",
    "        \n",
    "        # If lanes have too different curvature, detection is incorrect\n",
    "        if (min(abs(left_fit[0]), abs(right_fit[0])) < 2.0e-04\n",
    "            and abs(left_fit[0] - right_fit[0]) > 6.0e-04):\n",
    "            return False\n",
    "        \n",
    "        if (abs(left_fit[0] - right_fit[0]) > 10.0e-04):\n",
    "            return False\n",
    "        \n",
    "        min_dist = 550\n",
    "        max_dist = 850\n",
    "        \n",
    "        # If distance between lines (in the bootom of image) is too big or too small,\n",
    "        # lane was detected incorrectly\n",
    "        dist_bot = abs(left_fitx[G_H-1] - right_fitx[G_H-1])\n",
    "        if (dist_bot < min_dist or dist_bot > max_dist):\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def is_sharp_turn(self, lf, rf, lfx, rfx, threshold):\n",
    "        # sharp turn\n",
    "        if (abs(lf[0]) > threshold or abs(rf[0]) > threshold\n",
    "            or np.any(lfx < 50)\n",
    "            or np.any(rfx > 1230)):            \n",
    "            return True\n",
    "       \n",
    "        return False\n",
    "        \n",
    "    def is_flat_lane(self, lf, rf):\n",
    "        if (abs(lf[0]) < 2.0e-04 and abs(rf[0]) < 2.0e-04):           \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def reset_history(self):\n",
    "        del self.l_lane.recent_xfitted[:]\n",
    "        del self.r_lane.recent_xfitted[:]\n",
    "        del self.l_lane.recent_fit[:]\n",
    "        del self.r_lane.recent_fit[:]\n",
    "        self.history_len = 0\n",
    "        \n",
    "    def process_good_lane(self):\n",
    "        lf, rf = self.l_lane.current_fit, self.r_lane.current_fit\n",
    "        lfx, rfx = self.l_lane.allx, self.r_lane.allx\n",
    "        py = self.l_lane.ally\n",
    "        \n",
    "        is_good = True\n",
    "        if self.lost_frames >= self.MAX_LOST_FRAMES:\n",
    "            self.reset_view_range()\n",
    "            is_good, lf, rf, lfx, rfx = self.update_perspective(lf, rf, lfx, rfx)\n",
    "        elif self.is_sharp_turn(lf, rf, lfx, rfx, 3.5e-4):\n",
    "            self.decrease_view_range()\n",
    "            is_good, lf, rf, lfx, rfx = self.update_perspective(lf, rf, lfx, rfx)\n",
    "        elif self.is_flat_lane(lf, rf):\n",
    "            self.increase_view_range()\n",
    "            is_good, lf, rf, lfx, rfx = self.update_perspective(lf, rf, lfx, rfx)\n",
    "        \n",
    "        self.l_lane.current_fit = lf\n",
    "        self.r_lane.current_fit = rf\n",
    "        self.l_lane.allx = lfx\n",
    "        self.r_lane.allx = rfx\n",
    "        \n",
    "        if not is_good:\n",
    "            return False \n",
    "\n",
    "        self.l_lane.detected = True\n",
    "        self.r_lane.detected = True\n",
    "        self.lost_frames = 0\n",
    "        \n",
    "        self.l_lane.recent_xfitted.append(lfx)\n",
    "        self.r_lane.recent_xfitted.append(rfx)\n",
    "        self.l_lane.recent_fit.append(lf)\n",
    "        self.r_lane.recent_fit.append(rf)\n",
    "        self.history_len = len(self.l_lane.recent_xfitted)\n",
    "        if  self.history_len > self.HISTORY_SIZE:\n",
    "            self.l_lane.recent_xfitted.pop(0)\n",
    "            self.r_lane.recent_xfitted.pop(0)\n",
    "            self.l_lane.recent_fit.pop(0)\n",
    "            self.r_lane.recent_fit.pop(0)\n",
    "            self.history_len -= 1\n",
    "\n",
    "        # Calculate the radius of curvature in pixels for both lane lines\n",
    "        left_curverad, right_curverad, pos = measure_curvature_real(py, lfx, rfx)\n",
    "        self.l_lane.rad = left_curverad\n",
    "        self.r_lane.rad = right_curverad\n",
    "        \n",
    "        assert(self.history_len == len(self.l_lane.recent_xfitted))        \n",
    "        return True\n",
    "        \n",
    "    def process_bad_lane(self):\n",
    "        self.l_lane.detected = False\n",
    "        self.r_lane.detected = False\n",
    "\n",
    "        if self.history_len > 1:\n",
    "            self.l_lane.recent_xfitted.pop(0)\n",
    "            self.r_lane.recent_xfitted.pop(0)\n",
    "            self.l_lane.recent_fit.pop(0)\n",
    "            self.r_lane.recent_fit.pop(0)\n",
    "            self.history_len -= 1    \n",
    "        elif self.history_len == 0:\n",
    "            self.l_lane.bestx = None\n",
    "            self.r_lane.bestx = None            \n",
    "\n",
    "        self.lost_frames += 1\n",
    "        if self.lost_frames >= self.MAX_LOST_FRAMES:\n",
    "            # Reset perspective transform matrix\n",
    "            self.M, self.M_inv = self.def_M, self.def_M_inv\n",
    "            self.corners = self.def_corners\n",
    "            self.l_lane.bestx = None\n",
    "            self.r_lane.bestx = None\n",
    "            self.reset_history()\n",
    "    \n",
    "    def detect_lane(self, warped_bin_img):\n",
    "        if self.lost_frames < self.MAX_LOST_FRAMES:\n",
    "            ploty, lf, rf, lfx, rfx, vis_warped = search_around_poly(warped_bin_img,\n",
    "                                                                     self.l_lane.recent_fit[-1],\n",
    "                                                                     self.r_lane.recent_fit[-1])\n",
    "        else:\n",
    "            ploty, lf, rf, lfx, rfx, vis_warped = fit_polynomial(warped_bin_img, DBG)\n",
    "        \n",
    "        self.l_lane.allx = lfx\n",
    "        self.r_lane.allx = rfx\n",
    "        self.l_lane.current_fit = lf\n",
    "        self.r_lane.current_fit = rf\n",
    "        self.l_lane.ally = ploty\n",
    "        self.r_lane.ally = ploty\n",
    "        \n",
    "        return vis_warped\n",
    "    \n",
    "    def draw_text_info(self, img):\n",
    "        lf, rf = self.l_lane.current_fit, self.r_lane.current_fit\n",
    "        \n",
    "        if ((self.do_average and self.history_len >= self.MIN_FRAMES_TO_AVERAGE)\n",
    "             or (not self.do_average and self.history_len >= 1)):\n",
    "            color = (0, 255, 0)\n",
    "        else:\n",
    "            color = (255, 0, 0)\n",
    "            \n",
    "        txt_size_big = 0.8\n",
    "        txt_size = 0.5\n",
    "        txt_reg = 1\n",
    "        txt_bold = 2\n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        rad = '%.2f m' % self.curve if self.curve is not None else '-'\n",
    "        pos = '%.2f m' % self.lane_pos if self.lane_pos is not None else '-'\n",
    "        cv2.putText(img, 'Radius: ' + rad, (50, 50), font, txt_size_big, color, txt_bold, cv2.LINE_AA)\n",
    "        cv2.putText(img, 'Position: ' + pos, (50, 90), font, txt_size_big, color, txt_bold, cv2.LINE_AA)\n",
    "        \n",
    "        if self.do_debug: \n",
    "            if self.l_lane.detected:\n",
    "                color = (0, 255, 0)\n",
    "            else:\n",
    "                color = (255, 0, 0)\n",
    "            cv2.putText(img, 'Frame: %d' % self.frame ,\n",
    "                        (50, 140), font, txt_size, (0, 255, 0), txt_reg, cv2.LINE_AA)\n",
    "            cv2.putText(img, 'Found: ' + str(self.l_lane.detected and self.r_lane.detected),\n",
    "                        (200, 140), font, txt_size, color, txt_reg, cv2.LINE_AA)\n",
    "            cv2.putText(img, 'History len: ' + str(self.history_len),\n",
    "                        (340, 140), font, txt_size, (0, 255, 0), txt_reg, cv2.LINE_AA)\n",
    "            cv2.putText(img, 'Frames lost: ' + str(self.lost_frames),\n",
    "                        (480, 140), font, txt_size, (0, 255, 0), txt_reg, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(img, 'View range: ' + str(int(self.persp_rect_top)),\n",
    "                        (50, 160), font, txt_size, (0, 255, 0), txt_reg, cv2.LINE_AA)\n",
    "            cv2.putText(img, 'Warped pix: ' + str(self.warped_pixels),\n",
    "                        (200, 160), font, txt_size, (0, 255, 0), txt_reg, cv2.LINE_AA)  \n",
    "\n",
    "            if self.l_lane.allx is not None:\n",
    "                cv2.putText(img, 'Width bot: ' + str(abs(self.l_lane.allx[G_H-1] - self.r_lane.allx[G_H-1])),\n",
    "                            (380, 160), font, txt_size, (0, 255, 0), txt_reg, cv2.LINE_AA)\n",
    "\n",
    "            cv2.putText(img, 'Left fit: ' + str(lf),\n",
    "                        (50, 200), font, txt_size, color, txt_reg, cv2.LINE_AA)\n",
    "            cv2.putText(img, 'Right fit: ' + str(rf),\n",
    "                        (50, 220), font, txt_size, color, txt_reg, cv2.LINE_AA)\n",
    "            cv2.putText(img, 'Diff: ' + str(np.subtract(lf, rf)),\n",
    "                        (50, 240), font, txt_size, color, txt_reg, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(img, 'Best left fit: ' + str(self.l_lane.best_fit),\n",
    "                        (50, 280), font, txt_size, (0, 255, 0), txt_reg, cv2.LINE_AA)\n",
    "            cv2.putText(img, 'Best right fit: ' + str(self.r_lane.best_fit),\n",
    "                        (50, 300), font, txt_size, (0, 255, 0), txt_reg, cv2.LINE_AA)\n",
    "    \n",
    "        return img\n",
    "    \n",
    "    def __call__(self, img, dump_images = False, base = \"\", output_dir = \"\"):\n",
    "        # Undistort\n",
    "        undist = undistort(img)\n",
    "\n",
    "        # Make binary\n",
    "        bin_img, self.vis_bin = make_binary(undist)\n",
    "        \n",
    "        # Draw current perspective transform rectangle\n",
    "        cv2.polylines(self.vis_bin,\n",
    "                      [np.array(self.corners, dtype=np.int32).reshape((-1, 1, 2))],\n",
    "                      True,\n",
    "                      (255,255,0),\n",
    "                      thickness=2)\n",
    "        #\n",
    "        # Perspective transform\n",
    "        #\n",
    "        warped_bin_img = perspective_transform(bin_img, self.M)\n",
    "        self.warped_pixels = warped_bin_img.sum()\n",
    "        if self.warped_pixels < self.WARPED_PIXELS_THRES:\n",
    "            #\n",
    "            # Detect lane\n",
    "            #\n",
    "            vis_warped = self.detect_lane(warped_bin_img)\n",
    "            \n",
    "            #\n",
    "            # Process lanes info\n",
    "            #\n",
    "            is_good = self.is_good_lane(self.l_lane.current_fit,\n",
    "                                        self.r_lane.current_fit,\n",
    "                                        self.l_lane.allx,\n",
    "                                        self.r_lane.allx)\n",
    "            if is_good:\n",
    "                is_good = self.process_good_lane()\n",
    "            \n",
    "            if not is_good:\n",
    "                self.process_bad_lane()\n",
    "        \n",
    "            #\n",
    "            # Draw lane approximations on warped image\n",
    "            #\n",
    "            if is_good and self.l_lane.allx is not None:\n",
    "                cv2.polylines(vis_warped,\n",
    "                              [np.array([self.l_lane.allx, self.l_lane.ally], dtype=np.int32).T],\n",
    "                              False, (255, 0, 0), thickness=2)\n",
    "                cv2.polylines(vis_warped,\n",
    "                              [np.array([self.r_lane.allx, self.r_lane.ally], dtype=np.int32).T],\n",
    "                              False, (255, 0, 0), thickness=2)\n",
    "        else:\n",
    "            vis_warped = np.dstack((warped_bin_img, warped_bin_img, warped_bin_img)) * 255\n",
    "            self.process_bad_lane()\n",
    "            \n",
    "        \n",
    "        #\n",
    "        # Calculate and draw approximations\n",
    "        #       \n",
    "        if ((self.do_average and self.history_len >= self.MIN_FRAMES_TO_AVERAGE)\n",
    "             or (not self.do_average and self.history_len >= 1)):\n",
    "                       \n",
    "            self.l_lane.bestx = np.mean(self.l_lane.recent_xfitted, axis=0)\n",
    "            self.r_lane.bestx = np.mean(self.r_lane.recent_xfitted, axis=0)\n",
    "            self.l_lane.best_fit = np.mean(self.l_lane.recent_fit, axis=0)\n",
    "            self.r_lane.best_fit = np.mean(self.r_lane.recent_fit, axis=0)\n",
    "            \n",
    "            # Draw lane approximation\n",
    "            result = draw_lane(undist, warped, self.l_lane.bestx, self.r_lane.bestx, self.l_lane.ally, self.M_inv)\n",
    "        \n",
    "            # Calculate the radius of curvature in pixels for both lane lines\n",
    "            if self.do_average:\n",
    "                l_curve, r_curve, pos = measure_curvature_real(py, self.l_lane.bestx, self.r_lane.bestx)\n",
    "            else:\n",
    "                l_curve, r_curve, pos = measure_curvature_real(py, self.l_lane.allx, self.r_lane.allx)\n",
    "\n",
    "            self.curve = (l_curve + r_curve) / 2\n",
    "            self.lane_pos = pos\n",
    "        else:\n",
    "            result = undist\n",
    "            \n",
    "            self.curve = None\n",
    "            self.lane_pos = None\n",
    "        \n",
    "        result = self.draw_text_info(result)\n",
    "        self.frame += 1\n",
    "\n",
    "        if self.do_debug:\n",
    "            return np.concatenate((self.vis_bin, vis_warped, result), axis=1)\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "# Make a list of images\n",
    "images = glob.glob('test_images/*.jpg')\n",
    "images_count = len(images)\n",
    "fig, ax = plt.subplots(int((images_count + 1) / 2), 2, figsize=(10, 25))\n",
    "\n",
    "# Step through the list\n",
    "for idx, fname in enumerate(images):\n",
    "    t_img = cv2.imread(fname)\n",
    "    t_img = cv2.cvtColor(t_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Get base name\n",
    "    base = os.path.basename(fname)\n",
    "    base = os.path.splitext(base)[0]\n",
    "    \n",
    "    process_img = ProcessSeq(False, DBG, G_SRC_CORNERS, 100)\n",
    "    result = process_img(t_img, DBG, base, 'output_images')\n",
    "    \n",
    "    cv2.imwrite('output_images/res_' + base + '.jpg',\n",
    "                cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # plot original and final image\n",
    "    row = int(idx / 2)\n",
    "    col = idx % 2\n",
    "    ax[row, col].set_title(fname, fontsize=15)\n",
    "    ax[row, col].imshow(result)\n",
    "    \n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar\n",
    "\n",
    "ranges = [(450, 700),\n",
    "          (0, 480),\n",
    "          (0, 1280)]\n",
    "\n",
    "dump_range = [0, 1280]\n",
    "\n",
    "for vid, name in enumerate(clip_names):\n",
    "    process_img = ProcessSeq(True, DBG)\n",
    "    clip1 = VideoFileClip(name)\n",
    "\n",
    "    if vid == 2:\n",
    "        for idx, frame in enumerate(progressbar.log_progress(clip1.iter_frames(), every=1)):\n",
    "            if idx >= ranges[vid][0] and idx < max(ranges[vid][1], dump_range[1]):\n",
    "                result = process_img(frame)\n",
    "                \n",
    "                if idx >= dump_range[0] and idx < dump_range[1]:\n",
    "                    cv2.imwrite('output_dbg/vid' + str(vid) + '_dbg_' + str(idx) + '.jpg',\n",
    "                                cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "    clip1.close()\n",
    "\n",
    "frame_num = -1\n",
    "if frame_num >= 0:\n",
    "    frame = clip1.get_frame(float(frame_num)/clip1.fps)\n",
    "    cv2.imwrite('output_dbg/vid3_frame_' + str(frame_num) + '.jpg',\n",
    "                cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    result = process_img(frame)\n",
    "    cv2.imwrite('output_dbg/vid3_frame_' + str(frame_num) + '_out.jpg',\n",
    "                cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    clip1.close()\n",
    "#white_clip = clip1.fl_image(process_img) #NOTE: this function expects color images!!\n",
    "#%time white_clip.write_videofile('output_videos/project_video_out.mp4', audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = DBG\n",
    "debug_suffix = \"_dbg\" if debug else \"\"\n",
    "\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(ProcessSeq(True, debug))\n",
    "%time white_clip.write_videofile('output_videos/project_video_out' + debug_suffix + '.mp4', audio=False)\n",
    "clip1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = DBG\n",
    "debug_suffix = \"_dbg\" if debug else \"\"\n",
    "\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(ProcessSeq(True, debug))\n",
    "%time white_clip.write_videofile('output_videos/challenge_video_out' + debug_suffix + '.mp4', audio=False)\n",
    "clip1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = DBG\n",
    "debug_suffix = \"_dbg\" if debug else \"\"\n",
    "\n",
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(ProcessSeq(True, debug))\n",
    "%time white_clip.write_videofile('output_videos/harder_challenge_video_out' + debug_suffix + '.mp4', audio=False)\n",
    "clip1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window settings\n",
    "window_width = 50 \n",
    "window_height = 80 # Break image into 9 vertical layers since image height is 720\n",
    "margin = 100 # How much to slide left and right for searching\n",
    "\n",
    "def window_mask(width, height, img_ref, center,level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height),max(0,int(center-width/2)):min(int(center+width/2),img_ref.shape[1])] = 1\n",
    "    return output\n",
    "\n",
    "def find_window_centroids(image, window_width, window_height, margin):\n",
    "    \n",
    "    window_centroids = [] # Store the (left,right) window centroid positions per level\n",
    "    window = np.ones(window_width) # Create our window template that we will use for convolutions\n",
    "    \n",
    "    # First find the two starting positions for the left and right lane by using np.sum to get the vertical image slice\n",
    "    # and then np.convolve the vertical image slice with the window template \n",
    "    \n",
    "    # Sum quarter bottom of image to get slice, could use a different ratio\n",
    "    l_sum = np.sum(image[int(3*image.shape[0]/4):,:int(image.shape[1]/2)], axis=0)\n",
    "    l_center = np.argmax(np.convolve(window,l_sum))-window_width/2\n",
    "    \n",
    "    r_sum = np.sum(image[int(3*image.shape[0]/4):,int(image.shape[1]/2):], axis=0)\n",
    "    r_center = np.argmax(np.convolve(window,r_sum))-window_width/2+int(image.shape[1]/2)\n",
    "    \n",
    "    # Add what we found for the first layer\n",
    "    window_centroids.append((l_center,r_center))\n",
    "    \n",
    "    # Go through each layer looking for max pixel locations\n",
    "    for level in range(1,(int)(image.shape[0]/window_height)):\n",
    "        # convolve the window into the vertical slice of the image\n",
    "        image_layer = np.sum(image[int(image.shape[0]-(level+1)*window_height):int(image.shape[0]-level*window_height),:], axis=0)\n",
    "        conv_signal = np.convolve(window, image_layer)\n",
    "        \n",
    "        # Find the best left centroid by using past left center as a reference\n",
    "        # Use window_width/2 as offset because convolution signal reference is at right side of window, not center of window\n",
    "        offset = window_width/2\n",
    "        l_min_index = int(max(l_center + offset - margin,0))\n",
    "        l_max_index = int(min(l_center + offset + margin, image.shape[1]))\n",
    "        if np.any(conv_signal[l_min_index:l_max_index] > 0):\n",
    "            l_center = np.argmax(conv_signal[l_min_index:l_max_index]) + l_min_index - offset\n",
    "        \n",
    "        # Find the best right centroid by using past right center as a reference\n",
    "        r_min_index = int(max(r_center+offset-margin,0))\n",
    "        r_max_index = int(min(r_center+offset+margin,image.shape[1]))\n",
    "        if np.any(conv_signal[r_min_index:r_max_index] > 0):\n",
    "            r_center = np.argmax(conv_signal[r_min_index:r_max_index])+r_min_index-offset\n",
    "        \n",
    "        # Add what we found for that layer\n",
    "        window_centroids.append((l_center,r_center))\n",
    "\n",
    "    return window_centroids\n",
    "\n",
    "def search_conv(binary_warped):\n",
    "    window_centroids = find_window_centroids(binary_warped, window_width, window_height, margin)\n",
    "\n",
    "    # If we found any window centers\n",
    "    if len(window_centroids) > 0:\n",
    "\n",
    "        # Points used to draw all the left and right windows\n",
    "        l_points = np.zeros_like(binary_warped)\n",
    "        r_points = np.zeros_like(binary_warped)\n",
    "\n",
    "        # Go through each level and draw the windows \t\n",
    "        for level in range(0, len(window_centroids)):\n",
    "            # Window_mask is a function to draw window areas\n",
    "            l_mask = window_mask(window_width,window_height,binary_warped,window_centroids[level][0],level)\n",
    "            r_mask = window_mask(window_width,window_height,binary_warped,window_centroids[level][1],level)\n",
    "            # Add graphic points from window mask here to total pixels found \n",
    "            l_points[(l_mask == 1)] = 255\n",
    "            r_points[(r_mask == 1)] = 255\n",
    "\n",
    "        # Draw the results\n",
    "        template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "        zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "        template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "        warpage= np.dstack((binary_warped, binary_warped, binary_warped))*255 # making the original road pixels 3 color channels\n",
    "        output = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the orignal road image with window results\n",
    "\n",
    "    # If no window centers found, just display orginal road image\n",
    "    else:\n",
    "        output = np.array(cv2.merge((binary_warped,binary_warped,binary_warped)),np.uint8)\n",
    "        \n",
    "    return output\n",
    "\n",
    "output = search_conv(warped)\n",
    "# Display the final results\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(output)\n",
    "plt.title('window fitting results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "0c1bc3ff4bcf4018b524910802af4c20": {
     "views": []
    },
    "0cf2c2331f3a4005bfe3333883aab7e4": {
     "views": []
    },
    "127b830afdc64eb29e0626fb53e00c3a": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "1a47f50d592e4f1d9a7975940c169ed0": {
     "views": []
    },
    "29bd7f8bfc064848b1d11aece08462b5": {
     "views": []
    },
    "300d52c456e546248ae06a56f22afa23": {
     "views": []
    },
    "42e712cbee3345b887b955524ee33594": {
     "views": []
    },
    "5a8b01051edd42c5a49dbf7265a7f148": {
     "views": []
    },
    "7106ba20c2e64c31879caad3ae0aab4b": {
     "views": []
    },
    "7ce3bba62bb944d585fd20880421ecb1": {
     "views": []
    },
    "8ee0b6dad7a949498c053f882663f299": {
     "views": []
    },
    "a1b28f7ca9ab4f1e8966a12c92740037": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "aadb38428762484f9c2ae32f8f92026e": {
     "views": []
    },
    "b123556e75094501842c957dec326c30": {
     "views": []
    },
    "c08da5f56d7b4a71ba1b1d07498779d3": {
     "views": []
    },
    "d46f1356c9934521be1baf3c7ca52198": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "f966cbfd369e4c6ba15642dc8c235d0c": {
     "views": []
    },
    "fe9a93acd04747979ea88deb51ef86bd": {
     "views": []
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
