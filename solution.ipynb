{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress bar for jupyter: https://github.com/alexanderkuk/log-progress\n",
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib qt\n",
    "\n",
    "DBG = True\n",
    "NO_DBG = False\n",
    "CB_X = 6\n",
    "CB_Y = 9\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((CB_X * CB_Y, 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0 : CB_Y, 0 : CB_X].T.reshape(-1, 2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (CB_Y, CB_X), None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (CB_Y, CB_X), corners, ret)\n",
    "        #write_name = 'corners_found'+str(idx)+'.jpg'\n",
    "        #cv2.imwrite(write_name, img)\n",
    "        #cv2.imshow('img', img)\n",
    "        #cv2.waitKey(500)\n",
    "\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a distortion correction to raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Test undistortion on an image\n",
    "img = cv2.imread('camera_cal/calibration1.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "G_SHAPE = img.shape\n",
    "G_W = G_SHAPE[1]\n",
    "G_H = G_SHAPE[0]\n",
    "\n",
    "# Find camera calibration parameters given object points and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints,\n",
    "                                                   imgpoints,\n",
    "                                                   img_size,\n",
    "                                                   None,\n",
    "                                                   None)\n",
    "\n",
    "# Helper function to undistort images\n",
    "def undistort(img):\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return dst\n",
    "\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "dst = undistort(img)\n",
    "dst = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use color transforms, gradients, etc., to create a thresholded binary image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "fname = 'test_images/straight_lines2.jpg'\n",
    "img = mpimg.imread(fname) \n",
    "\n",
    "clip_names = [\"project_video.mp4\",\n",
    "              \"challenge_video.mp4\",\n",
    "              \"harder_challenge_video.mp4\"]\n",
    "\n",
    "frame_num = 664\n",
    "clip1 = VideoFileClip(clip_names[2])\n",
    "img = clip1.get_frame(float(frame_num)/clip1.fps)\n",
    "clip1.close()\n",
    "\n",
    "\n",
    "# Define a function that thresholds the S-channel of HLS\n",
    "# Use exclusive lower bound (>) and inclusive upper (<=)\n",
    "def hls_select(channel, thresh=(0, 255), ch='s'):\n",
    "    # 1) Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    # 2) Apply a threshold to the S channel\n",
    "    channel = 0\n",
    "    if ch == 'h':\n",
    "        channel = hls[:,:,0]\n",
    "    elif ch == 'l':\n",
    "        channel = hls[:,:,1]\n",
    "    else:\n",
    "        channel = hls[:,:,2]\n",
    "    \n",
    "    binary = np.zeros_like(channel)\n",
    "    binary[(channel > thresh[0]) & (channel <= thresh[1])] = 1\n",
    "    # 3) Return a binary image of threshold result\n",
    "    return binary\n",
    "\n",
    "def channel_select(channel, thresh=(0, 255)):\n",
    "    binary = np.zeros_like(channel)\n",
    "    binary[(channel > thresh[0]) & (channel <= thresh[1])] = 1\n",
    "    # 3) Return a binary image of threshold result\n",
    "    return binary\n",
    "\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "    \n",
    "hls_binary = hls_select(img, thresh=(90, 255))\n",
    "\n",
    "# Plot different channels\n",
    "G_CLACHE = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "G_CLACHE_STR = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8, 8))\n",
    "hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "h_channel = hls[:,:,0]\n",
    "l_channel = hls[:,:,1]\n",
    "s_channel = hls[:,:,2]\n",
    "\n",
    "r_channel = img[:,:,0]\n",
    "g_channel = img[:,:,1]\n",
    "b_channel = img[:,:,2]\n",
    "\n",
    "r_cl = G_CLACHE.apply(r_channel)\n",
    "g_cl = G_CLACHE.apply(g_channel)\n",
    "s_cl = G_CLACHE.apply(s_channel)\n",
    "\n",
    "wl = np.uint8(r_channel*0.299 + g_channel*0.587 + b_channel*0.1170)\n",
    "wl_cl = G_CLACHE.apply(wl)\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "cl = G_CLACHE.apply(gray)\n",
    "\n",
    "\n",
    "#f, (ax) = plt.subplots(3, 2, figsize=(15, 15))\n",
    "#ax[0, 0].imshow(h_channel, cmap='gray')\n",
    "#ax[0, 0].set_title('H channel', fontsize=50)\n",
    "#ax[0, 1].imshow(l_channel, cmap='gray')\n",
    "#ax[0, 1].set_title('L channel', fontsize=50)\n",
    "#ax[1, 0].imshow(s_channel, cmap='gray')\n",
    "#ax[1, 0].set_title('S channel', fontsize=50)\n",
    "#ax[1, 1].imshow(r_channel, cmap='gray')\n",
    "#ax[1, 1].set_title('R channel', fontsize=50)\n",
    "#ax[2, 0].imshow(g_channel, cmap='gray')\n",
    "#ax[2, 0].set_title('G channel', fontsize=50)\n",
    "#ax[2, 1].imshow(b_channel, cmap='gray')\n",
    "#ax[2, 1].set_title('B channel', fontsize=50)\n",
    "\n",
    "f, (ax) = plt.subplots(5, 2, figsize=(10, 15))\n",
    "ax[0, 0].imshow(r_channel, cmap='gray')\n",
    "ax[0, 0].set_title('R channel', fontsize=20)\n",
    "ax[0, 1].imshow(r_cl, cmap='gray')\n",
    "ax[0, 1].set_title('R clache', fontsize=20)\n",
    "ax[1, 0].imshow(wl, cmap='gray')\n",
    "ax[1, 0].set_title('W3C lightness', fontsize=20)\n",
    "ax[1, 1].imshow(s_channel, cmap='gray')\n",
    "ax[1, 1].set_title('S channel', fontsize=20)\n",
    "\n",
    "ax[2, 0].imshow(l_channel, cmap='gray')\n",
    "ax[2, 0].set_title('L channel', fontsize=20)\n",
    "ax[2, 1].imshow(s_channel, cmap='gray')\n",
    "ax[2, 1].set_title('S clache', fontsize=20)\n",
    "ax[3, 0].imshow(gray, cmap='gray')\n",
    "ax[3, 0].set_title('Gray', fontsize=20)\n",
    "ax[3, 1].imshow(cl, cmap='gray')\n",
    "ax[3, 1].set_title('Gray clache', fontsize=20)\n",
    "ax[4, 0].imshow(wl, cmap='gray')\n",
    "ax[4, 0].set_title('weighted light', fontsize=20)\n",
    "ax[4, 1].imshow(wl_cl, cmap='gray')\n",
    "ax[4, 1].set_title('weighted light clache', fontsize=20)\n",
    "\n",
    "\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', thresh=(0, 255)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel > thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def abs_sobel_thresh_hls(img, orient='x', thresh=(0, 255)):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)[:,:,2]\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(hls, cv2.CV_64F, 1, 0)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(hls, cv2.CV_64F, 0, 1)\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel > thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def abs_raw_sobel(channel, orient='x', thresh=(30, 255)):\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(channel, cv2.CV_64F, 1, 0)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(channel, cv2.CV_64F, 0, 1)\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel > thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def mag_thresh(gray, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    #gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    mag = np.sqrt(np.square(sobelx) + np.square(sobely))\n",
    "    scaled_mag = np.uint8(255*mag/np.max(mag))\n",
    "    binary_output = np.zeros_like(scaled_mag)\n",
    "    binary_output[(scaled_mag >= mag_thresh[0]) & (scaled_mag <= mag_thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def dir_thresh(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    abs_sobelx = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    abs_sobely = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "    dir = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    binary_output = np.zeros_like(dir, dtype=np.uint8)\n",
    "    binary_output[(dir >= thresh[0]) & (dir <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "    \n",
    "# Run the function\n",
    "x_sobel = abs_raw_sobel(cl, 'x', (15, 255))\n",
    "y_sobel = abs_raw_sobel(cl, 'y', (15, 255))\n",
    "mag_sobel = mag_thresh(cl, 5, (15, 255))\n",
    "dir_sobel = dir_thresh(img, sobel_kernel=15, thresh=(0.95, 1.05)) #thresh=(0.7, 1.3))\n",
    "sobel_S = abs_raw_sobel(s_channel, 'x', (20, 255))\n",
    "x_sobel_R = abs_raw_sobel(r_cl, 'x', (20, 255))\n",
    "cny = canny(img, 50, 150)\n",
    "\n",
    "# Plot the result\n",
    "f, ax = plt.subplots(4, 2, figsize=(15, 20))\n",
    "ax[0, 0].imshow(x_sobel, cmap='gray')\n",
    "ax[0, 0].set_title('X sobel', fontsize=30)\n",
    "ax[0, 1].imshow(y_sobel, cmap='gray')\n",
    "ax[0, 1].set_title('Y sobel', fontsize=30)\n",
    "ax[1, 0].imshow(mag_sobel, cmap='gray')\n",
    "ax[1, 0].set_title('Mag sobel', fontsize=30)\n",
    "ax[1, 1].imshow(dir_sobel, cmap='gray')\n",
    "ax[1, 1].set_title('Dir sobel', fontsize=30)\n",
    "ax[2, 0].imshow(sobel_S, cmap='gray')\n",
    "ax[2, 0].set_title('Sobel S', fontsize=30)\n",
    "ax[2, 1].imshow(x_sobel_R, cmap='gray')\n",
    "ax[2, 1].set_title('Sobel R', fontsize=30)\n",
    "ax[3, 0].imshow(cny, cmap='gray')\n",
    "ax[3, 0].set_title('Canny', fontsize=20)\n",
    "\n",
    "\n",
    "#f.tight_layout()\n",
    "#ax1.imshow(image)\n",
    "#ax1.set_title('Original Image', fontsize=50)\n",
    "#ax2.imshow(mag_binary, cmap='gray')\n",
    "#ax2.set_title('Thresholded Image', fontsize=50)\n",
    "#plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "undist = undistort(img)\n",
    "\n",
    "# Edit this function to create your own pipeline.\n",
    "def make_binary(img):\n",
    "    img = np.copy(img)\n",
    "    \n",
    "    # \n",
    "    # Prepare masks\n",
    "    #\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    R_channel = img[:,:,0]\n",
    "    G_channel = img[:,:,1]\n",
    "    B_channel = img[:,:,2]\n",
    "    \n",
    "    H_channel = hls[:,:,0]\n",
    "    L_channel = hls[:,:,1]\n",
    "    S_channel = hls[:,:,2]\n",
    "    \n",
    "    wl = np.uint8(R_channel*0.299 + G_channel*0.587 + B_channel*0.1170)\n",
    "    gray_cl = G_CLACHE.apply(gray)\n",
    "    gray_cl_bl = gaussian_blur(gray_cl, 5)\n",
    "    gray_cl_bl_bl = gaussian_blur(gray_cl_bl, 5)\n",
    "\n",
    "    # Gray mask\n",
    "    gray_reg = np.zeros_like(gray)\n",
    "    diff1 = abs(np.int32(R_channel) - np.int32(G_channel))\n",
    "    diff2 = abs(np.int32(G_channel) - np.int32(B_channel))\n",
    "    diff3 = abs(np.int32(R_channel) - np.int32(B_channel))\n",
    "    gray_reg[(diff1 <= 25) & (diff2 <= 25) & (diff3 <= 25)] = 1\n",
    "    gray_reg_er = cv2.erode(gray_reg, np.ones((5,5)), iterations = 2)\n",
    "    \n",
    "    # Gray mask + white lanes\n",
    "    white_mask = channel_select(gray, (180, 255))\n",
    "    white_mask = cv2.dilate(white_mask, np.ones((5,5)), iterations = 1)\n",
    "    gray_and_white_reg = np.copy(gray_reg)\n",
    "    gray_and_white_reg[(white_mask == 1)] = 0\n",
    "    \n",
    "    # Colored mask\n",
    "    color_reg = np.zeros_like(gray)\n",
    "    color_reg[(diff1 > 15) & (diff2 > 15) & (diff3 > 15)] = 1\n",
    "    color_reg_cl = cv2.dilate(color_reg, np.ones((5,5)), iterations = 1)\n",
    "    color_reg_er = cv2.erode(color_reg, np.ones((5,5)), iterations = 2)\n",
    "     \n",
    "    # Dark blue mask\n",
    "    dark_blue_reg = np.zeros_like(gray)\n",
    "    diff1 = (np.int32(B_channel) - np.int32(G_channel))\n",
    "    diff2 = (np.int32(B_channel) - np.int32(R_channel))\n",
    "    dark_blue_reg[(diff1 > 10) & (diff2 > 10)] = 1\n",
    "    dark_blue_reg[(gray_cl >= 90)] = 0\n",
    "    dark_blue_reg_dl = cv2.dilate(dark_blue_reg, np.ones((5,5)), iterations = 1)\n",
    "    dark_blue_reg_er = cv2.erode(dark_blue_reg, np.ones((5,5)), iterations = 2)\n",
    "    \n",
    "    gray_cl = G_CLACHE.apply(gray)\n",
    "    R_channel_cl = G_CLACHE.apply(img[:,:,0])\n",
    "    G_channel_cl = G_CLACHE.apply(img[:,:,1])\n",
    "    B_channel_cl = G_CLACHE.apply(img[:,:,2])\n",
    "    \n",
    "    # sobel y\n",
    "    sobel_y = abs_raw_sobel(gray_cl, 'y', (15, 255))\n",
    "    sobel_y_cl = cv2.dilate(color_reg, np.ones((5,5)), iterations = 1)\n",
    "    \n",
    "    #\n",
    "    # Do thresholding\n",
    "    #\n",
    "    \n",
    "    # 1. Threshold HLS\n",
    "    S_sobel = abs_raw_sobel(S_channel, 'x', (30, 255))\n",
    "    HLS_binary = S_sobel\n",
    "    HLS_binary[(color_reg_er == 1)] = 0\n",
    "    HLS_binary[(gray_reg_er == 1)] = 0\n",
    "    \n",
    "    \n",
    "    # 2. Threshold based on sobel edge detection\n",
    "    sobel_x = abs_raw_sobel(gray_cl, 'x', (30, 255))\n",
    "    sobel_x[(gray_and_white_reg == 1)] = 0\n",
    "    \n",
    "    sobel_strong = abs_raw_sobel(gray_cl, 'x', (15, 255))\n",
    "    wl_mask = channel_select(wl, (100, 255))\n",
    "    wl_mask_dl = cv2.dilate(wl_mask, np.ones((5,5)), iterations = 1)\n",
    "    high_S = channel_select(S_channel, (40, 255))\n",
    "    high_S_dl = cv2.dilate(high_S, np.ones((5,5)), iterations = 1)\n",
    "    sobel_dark = np.copy(sobel_strong)\n",
    "    sobel_dark[wl_mask_dl == 1] = 0\n",
    "    #sobel_dark[high_S_dl == 0] = 0\n",
    "    \n",
    "    sobel_dark_blue = np.copy(dark_blue_reg_dl)\n",
    "    sobel_dark_blue[(sobel_strong == 0)] = 0\n",
    "    sobel_dark_blue[(high_S_dl == 0)] = 0\n",
    "       \n",
    "    sobel = sobel_x | sobel_dark | sobel_dark_blue              \n",
    "            \n",
    "    # 3. Color threshold\n",
    "    RGB_binary = np.zeros_like(gray_cl)\n",
    "    \n",
    "    # Yellow filter\n",
    "    # (Good detection of yellow lane on challenge video)\n",
    "    R_filtered = channel_select(R_channel_cl, (160, 255))\n",
    "    G_filtered = channel_select(G_channel_cl, (160, 255))\n",
    "    B_filtered = channel_select(B_channel_cl, (0, 130))\n",
    "    RGB_binary[(R_filtered == 1) & (G_filtered == 1) & (B_filtered == 1)] = 1\n",
    "    \n",
    "    # White filter      \n",
    "    white_sel = channel_select(gray_cl, (210, 255))\n",
    "    L_filtered = channel_select(wl, (0, 150))\n",
    "    L_dilated = cv2.dilate(L_filtered, np.ones((5,5)), iterations = 1)\n",
    "    white_sel[(L_dilated != 1)] = 0\n",
    "    \n",
    "    sobel_light = abs_raw_sobel(wl, 'x', (25, 255))\n",
    "    L_filtered = channel_select(wl, (0, 120))\n",
    "    L_dilated = cv2.dilate(L_filtered, np.ones((5,5)), iterations = 1)\n",
    "    sobel_light[(L_dilated == 1)] = 0\n",
    "    RGB_binary[(white_sel == 1) | (sobel_light == 1)] = 1\n",
    "    RGB_binary[(color_reg_er == 1)] = 0\n",
    "\n",
    "    #\n",
    "    # Output\n",
    "    #\n",
    "    \n",
    "    dbg = np.dstack((dark_blue_reg, dark_blue_reg, dark_blue_reg)) * 255\n",
    "    color_binary = np.dstack((HLS_binary, sobel, RGB_binary)) * 255\n",
    "    #color_binary = np.concatenate((color_binary, dbg), axis = 1)\n",
    "    \n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sobel)\n",
    "    combined_binary[(HLS_binary == 1) | (sobel == 1) | (RGB_binary == 1)] = 1\n",
    "    return (combined_binary, color_binary)\n",
    "    \n",
    "(comb_bin, col_bin) = make_binary(undist)\n",
    "\n",
    "# Plot the result\n",
    "#f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "#f, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 25))\n",
    "\n",
    "#ax1.imshow(img)\n",
    "#ax1.set_title('Original Image', fontsize=20)\n",
    "\n",
    "#ax2.imshow(col_bin)\n",
    "#ax2.set_title('Pipeline Result', fontsize=20)\n",
    "\n",
    "#ax3.imshow(comb_bin, cmap='gray')\n",
    "#ax3.set_title('Combined binary', fontsize=20)\n",
    "\n",
    "#base = os.path.splitext(os.path.basename(fname))[0]\n",
    "#mpimg.imsave('output_dbg/dbg_' + base + '.png', res)\n",
    "\n",
    "# vid1 548;\n",
    "# vid2 80 - 4 lanes\n",
    "#      131 - tunnel\n",
    "#      152 - after tunnel\n",
    "frames = [[], #[548],\n",
    "          [], #[0, 12, 29, 80, 125, 131, 145, 152, 157, 263, 451],\n",
    "          [0, 175, 185, 281, 284, 310, 337, 338, 344, 580, 664]]\n",
    "\n",
    "for idx, clip_name in enumerate(clip_names):\n",
    "    clip1 = VideoFileClip(clip_name)\n",
    "\n",
    "    for frame_num in frames[idx]:\n",
    "        timg = clip1.get_frame(float(frame_num)/clip1.fps)\n",
    "        und = undistort(timg)\n",
    "        (binary, dbg) = make_binary(und)\n",
    "        dbg = np.concatenate((und, dbg), axis=1)\n",
    "        mpimg.imsave('output_dbg/a_vid' + str(idx) + '_dbg_' + str(frame_num) + '.png', dbg)\n",
    "        \n",
    "    clip1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective rectangle detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "import  math\n",
    "\n",
    "Y_EDGE = 500\n",
    "X_MARGIN = 500\n",
    "Y_MARGIN = 460\n",
    "X_MIDDLE = G_SHAPE[1] / 2\n",
    "# Crop region of interest \n",
    "CROP_REC = [[0, G_SHAPE[0]], # left bottom\n",
    "            #[0, G_SHAPE[0] - Y_MARGIN],\n",
    "            [X_MARGIN, Y_EDGE], # left top\n",
    "            [G_SHAPE[1] - X_MARGIN, Y_EDGE], # right top\n",
    "            #[SHAPE[1], SHAPE[0] - Y_MARGIN],\n",
    "            [G_SHAPE[1], G_SHAPE[0]]] # right bottom\n",
    "\n",
    "VOTES = 15\n",
    "LINE_PIX = 25\n",
    "MAX_GAP = 30\n",
    "\n",
    "LMARGIN = 220\n",
    "HMARGIN = 515\n",
    "#src_corners = [[150, img_size[1]], # left bottom\n",
    "#               [640, 460], # left top\n",
    "#               [700, 460], # right top\n",
    "#               [1035, img_size[1]]] # right bottom\n",
    "\n",
    "G_SRC_CORNERS = [[LMARGIN, G_H], # left bottom\n",
    "                 [HMARGIN, Y_EDGE], # left top\n",
    "                 [G_W - HMARGIN, Y_EDGE], # right top\n",
    "                 [G_W - LMARGIN, G_H]] # right bottom\n",
    "\n",
    "G_DST_CORNERS = [[280, img_size[1]], [280, 0], [1000, 0], [1000, img_size[1]]]\n",
    "\n",
    "# Helper class\n",
    "class RefPoints:\n",
    "    def __init__(self, y_ed, x_mi):\n",
    "        self.y_edge = y_ed       # y coordinate of the top edge of clip region\n",
    "        self.x_middle = x_mi     # x coordinate of the middle of the top edge\n",
    "                                 # of clip region\n",
    "\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)\n",
    "\n",
    "def find_line(x_dots, y_dots, ref_pts):\n",
    "    if x_dots is not None:\n",
    "        A = np.vstack([x_dots, np.ones(len(x_dots))]).T     \n",
    "        m, c = np.linalg.lstsq(A, y_dots)[0]\n",
    "        x1 = int((img.shape[0] - c)/m)\n",
    "        y1 = int(img.shape[0])\n",
    "        x2 = int((ref_pts.y_edge - c)/m)\n",
    "        y2 = int(ref_pts.y_edge)\n",
    "        return [(x1, y1), (x2, y2)]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def detect_lines(lines, ref_pts, dbg_img):\n",
    "    if lines is None:\n",
    "        return None, None\n",
    "    \n",
    "    if lines.size == 0:\n",
    "        return None, None\n",
    "    \n",
    "    left_x = [] # x coordinates of left lane dots\n",
    "    left_y = [] # y coordinates of left lane dots\n",
    "    right_x = [] # x coordinates of right lane dots\n",
    "    right_y = [] # y coordinates of right lane dots|\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            slope = (y2-y1)/float(x2-x1)\n",
    "            \n",
    "            if x1 > ref_pts.x_middle and x2 > ref_pts.x_middle and slope >= 0.5 and slope <= 1:\n",
    "                right_x.extend([x1, x2])\n",
    "                right_y.extend([y1, y2])\n",
    "                cv2.line(dbg_img, (x1, y1), (x2, y2), [0, 255, 0], 2)\n",
    "            elif x1 < ref_pts.x_middle and x2 < ref_pts.x_middle and slope >= -1 and slope <= -0.5:\n",
    "                left_x.extend([x1, x2])\n",
    "                left_y.extend([y1, y2])\n",
    "                cv2.line(dbg_img, (x1, y1), (x2, y2), [0, 0, 255], 2)\n",
    "    \n",
    "    l_line = find_line(left_x, left_y, ref_pts)\n",
    "    r_line = find_line(right_x, right_y, ref_pts)\n",
    "       \n",
    "    return l_line, r_line\n",
    "\n",
    "def calc_persp_matr(l_line, r_line, rect_top_width):\n",
    "    if l_line is not None:\n",
    "        (x1, y1) = l_line[0]\n",
    "        (x2, y2) = l_line[1]\n",
    "        (x3, y3) = r_line[0]\n",
    "        (x4, y4) = r_line[1]\n",
    "\n",
    "        L = x2 - x1\n",
    "        R = x3 - x4\n",
    "        W_top = x4 - x2\n",
    "        H = y1 - y2\n",
    "         \n",
    "        if L > 0 and R > 0 and W_top > 0 and H > 0 and x1 > 0 and x3 < G_W:\n",
    "            off = (float(rect_top_width) - W_top) * H / (L + R)                  \n",
    "\n",
    "            src = np.float32([l_line[0],\n",
    "                              (x2 - L * off / H, y2 + off),\n",
    "                              (x4 + R * off / H, y4 + off),\n",
    "                              r_line[0]])\n",
    "\n",
    "            dst = np.float32(G_DST_CORNERS)\n",
    "            M = cv2.getPerspectiveTransform(src, dst)\n",
    "            M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "            return M, M_inv, src\n",
    "    \n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a perspective transform to rectify binary image (\"birds-eye view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = np.float32(G_SRC_CORNERS)\n",
    "dst = np.float32(G_DST_CORNERS)\n",
    "m = cv2.getPerspectiveTransform(src, dst)\n",
    "m_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "G_M = m\n",
    "G_M_inv = m_inv\n",
    "corners = G_SRC_CORNERS\n",
    "\n",
    "def perspective_transform(img, M, debug = False):  \n",
    "    warped = cv2.warpPerspective(img,\n",
    "                                 M,\n",
    "                                 (img.shape[1], img.shape[0]),\n",
    "                                 flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warped\n",
    "\n",
    "warped = perspective_transform(comb_bin, m)\n",
    "\n",
    "# Plot the result\n",
    "colored_comb_bin = np.dstack((comb_bin, comb_bin, comb_bin)) * 255\n",
    "cv2.polylines(colored_comb_bin,\n",
    "              [np.array(corners, dtype=np.int32).reshape((-1, 1, 2))],\n",
    "              True,\n",
    "              (255,0,0),\n",
    "              thickness = 2)\n",
    "cv2.polylines(colored_comb_bin,\n",
    "              [np.array(G_SRC_CORNERS,dtype=np.int32).reshape((-1, 1, 2))],\n",
    "              True,\n",
    "              (255,255,0),\n",
    "              thickness = 2)\n",
    "\n",
    "colored_warped = np.dstack((warped, warped, warped)) * 255\n",
    "cv2.polylines(colored_warped,\n",
    "              [np.array(G_DST_CORNERS, dtype=np.int32).reshape((-1, 1, 2))],\n",
    "              True,\n",
    "              (255,255,0),\n",
    "              thickness=2)\n",
    "\n",
    "#f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 15))\n",
    "f.tight_layout()\n",
    "\n",
    "ax1.imshow(colored_comb_bin)\n",
    "ax1.set_title('Binary', fontsize=40)\n",
    "\n",
    "ax2.imshow(colored_warped)\n",
    "ax2.set_title('Warped', fontsize=40)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect lane pixels and fit to find the lane boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_pixels(binary_warped, vis):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = 0\n",
    "    if vis:\n",
    "        out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 150\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    left_off = 0\n",
    "    right_off = 0\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        \n",
    "        ##Find the four below boundaries of the window\n",
    "        win_xleft_low = leftx_current  - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        if vis:\n",
    "            cv2.rectangle(out_img,\n",
    "                          (win_xleft_low,win_y_low),\n",
    "                          (win_xleft_high,win_y_high),\n",
    "                          (0,255,0),\n",
    "                          2) \n",
    "            cv2.rectangle(out_img,\n",
    "                          (win_xright_low,win_y_low),\n",
    "                          (win_xright_high,win_y_high),\n",
    "                          (0,255,0),\n",
    "                          2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        \n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If found > minpix pixels, recenter next window\n",
    "        # (`right` or `leftx_current`) on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_mean = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            leftx_current = leftx_mean\n",
    "            \n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_mean = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "            rightx_current = rightx_mean\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "def fit_polynomial(binary_warped, vis):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped, vis)\n",
    "\n",
    "    # Fit a second order polynomial to each using `np.polyfit` ###\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    if vis:\n",
    "        # Colors in the left and right lane regions\n",
    "        out_img[lefty, leftx] = [255, 0, 0]\n",
    "        out_img[righty, rightx] = [0, 0, 255]\n",
    "        cv2.polylines(out_img,\n",
    "                      [np.array([left_fitx, ploty], dtype=np.int32).T],\n",
    "                      False,\n",
    "                      (255,255,0),\n",
    "                      thickness=2)\n",
    "        cv2.polylines(out_img,\n",
    "                      [np.array([right_fitx, ploty], dtype=np.int32).T],\n",
    "                      False,\n",
    "                      (255,255,0),\n",
    "                      thickness=2)\n",
    "        \n",
    "\n",
    "    return ploty, left_fit, right_fit, left_fitx, right_fitx, out_img\n",
    "\n",
    "py, lf, rf, lfx, rfx, vis = fit_polynomial(warped, True)\n",
    "\n",
    "# Plots the left and right polynomials on the lane lines\n",
    "plt.figure(figsize=(15, 15))\n",
    "#plt.plot(lfx, py, color='yellow')\n",
    "#plt.plot(rfx, py, color='yellow')\n",
    "plt.imshow(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window settings\n",
    "window_width = 50 \n",
    "window_height = 80 # Break image into 9 vertical layers since image height is 720\n",
    "margin = 100 # How much to slide left and right for searching\n",
    "\n",
    "def window_mask(width, height, img_ref, center,level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height),max(0,int(center-width/2)):min(int(center+width/2),img_ref.shape[1])] = 1\n",
    "    return output\n",
    "\n",
    "def find_window_centroids(image, window_width, window_height, margin):\n",
    "    \n",
    "    window_centroids = [] # Store the (left,right) window centroid positions per level\n",
    "    window = np.ones(window_width) # Create our window template that we will use for convolutions\n",
    "    \n",
    "    # First find the two starting positions for the left and right lane by using np.sum to get the vertical image slice\n",
    "    # and then np.convolve the vertical image slice with the window template \n",
    "    \n",
    "    # Sum quarter bottom of image to get slice, could use a different ratio\n",
    "    l_sum = np.sum(image[int(3*image.shape[0]/4):,:int(image.shape[1]/2)], axis=0)\n",
    "    l_center = np.argmax(np.convolve(window,l_sum))-window_width/2\n",
    "    \n",
    "    r_sum = np.sum(image[int(3*image.shape[0]/4):,int(image.shape[1]/2):], axis=0)\n",
    "    r_center = np.argmax(np.convolve(window,r_sum))-window_width/2+int(image.shape[1]/2)\n",
    "    \n",
    "    # Add what we found for the first layer\n",
    "    window_centroids.append((l_center,r_center))\n",
    "    \n",
    "    # Go through each layer looking for max pixel locations\n",
    "    for level in range(1,(int)(image.shape[0]/window_height)):\n",
    "        # convolve the window into the vertical slice of the image\n",
    "        image_layer = np.sum(image[int(image.shape[0]-(level+1)*window_height):int(image.shape[0]-level*window_height),:], axis=0)\n",
    "        conv_signal = np.convolve(window, image_layer)\n",
    "        \n",
    "        # Find the best left centroid by using past left center as a reference\n",
    "        # Use window_width/2 as offset because convolution signal reference is at right side of window, not center of window\n",
    "        offset = window_width/2\n",
    "        l_min_index = int(max(l_center + offset - margin,0))\n",
    "        l_max_index = int(min(l_center + offset + margin, image.shape[1]))\n",
    "        if np.any(conv_signal[l_min_index:l_max_index] > 0):\n",
    "            l_center = np.argmax(conv_signal[l_min_index:l_max_index]) + l_min_index - offset\n",
    "        \n",
    "        # Find the best right centroid by using past right center as a reference\n",
    "        r_min_index = int(max(r_center+offset-margin,0))\n",
    "        r_max_index = int(min(r_center+offset+margin,image.shape[1]))\n",
    "        if np.any(conv_signal[r_min_index:r_max_index] > 0):\n",
    "            r_center = np.argmax(conv_signal[r_min_index:r_max_index])+r_min_index-offset\n",
    "        \n",
    "        # Add what we found for that layer\n",
    "        window_centroids.append((l_center,r_center))\n",
    "\n",
    "    return window_centroids\n",
    "\n",
    "def search_conv(binary_warped):\n",
    "    window_centroids = find_window_centroids(binary_warped, window_width, window_height, margin)\n",
    "\n",
    "    # If we found any window centers\n",
    "    if len(window_centroids) > 0:\n",
    "\n",
    "        # Points used to draw all the left and right windows\n",
    "        l_points = np.zeros_like(binary_warped)\n",
    "        r_points = np.zeros_like(binary_warped)\n",
    "\n",
    "        # Go through each level and draw the windows \t\n",
    "        for level in range(0, len(window_centroids)):\n",
    "            # Window_mask is a function to draw window areas\n",
    "            l_mask = window_mask(window_width,window_height,binary_warped,window_centroids[level][0],level)\n",
    "            r_mask = window_mask(window_width,window_height,binary_warped,window_centroids[level][1],level)\n",
    "            # Add graphic points from window mask here to total pixels found \n",
    "            l_points[(l_mask == 1)] = 255\n",
    "            r_points[(r_mask == 1)] = 255\n",
    "\n",
    "        # Draw the results\n",
    "        template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "        zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "        template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "        warpage= np.dstack((binary_warped, binary_warped, binary_warped))*255 # making the original road pixels 3 color channels\n",
    "        output = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the orignal road image with window results\n",
    "\n",
    "    # If no window centers found, just display orginal road image\n",
    "    else:\n",
    "        output = np.array(cv2.merge((binary_warped,binary_warped,binary_warped)),np.uint8)\n",
    "        \n",
    "    return output\n",
    "\n",
    "output = search_conv(warped)\n",
    "# Display the final results\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(output)\n",
    "plt.title('window fitting results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search from prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_poly(leftx, lefty, rightx, righty):\n",
    "    # Fit a second order polynomial to each with np.polyfit()\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    return left_fit, right_fit\n",
    "    \n",
    "def find_poly_values(left_fit, right_fit, img_shape):\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, G_H - 1, G_H)\n",
    "    # Calc both polynomials using ploty, left_fit and right_fit ###\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    return left_fitx, right_fitx, ploty\n",
    "\n",
    "def search_around_poly(binary_warped, left_fit, right_fit):\n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    # The quiz grader expects 100 here, but feel free to tune on your own!\n",
    "    margin = 70\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    ### TO-DO: Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "    ### Hint: consider the window areas for the similarly named variables ###\n",
    "    ### in the previous quiz, but change the windows to our new search area ###\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    \n",
    "    min_found = 500\n",
    "    new_left_fit, new_right_fit = None, None\n",
    "    if len(leftx) < min_found or len(rightx) < min_found:\n",
    "        new_left_fit = left_fit\n",
    "        new_right_fit = right_fit\n",
    "        ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "        return ploty, new_left_fit, new_right_fit, None, None, out_img  \n",
    "    \n",
    "    # Fit new polynomials\n",
    "    new_left_fit, new_right_fit = fit_poly(leftx, lefty, rightx, righty)\n",
    "    \n",
    "    if (lefty < 360).sum() <= 10:\n",
    "        A = np.vstack([lefty, np.ones(len(lefty))]).T     \n",
    "        k, b = np.linalg.lstsq(A, leftx)[0]\n",
    "        new_left_fit[0] = 0\n",
    "        new_left_fit[1] = k\n",
    "        new_left_fit[2] = b\n",
    "        \n",
    "    if (righty < 360).sum() <= 10:\n",
    "        A = np.vstack([righty, np.ones(len(righty))]).T     \n",
    "        k, b = np.linalg.lstsq(A, rightx)[0]\n",
    "        new_right_fit[0] = 0\n",
    "        new_right_fit[1] = k\n",
    "        new_right_fit[2] = b\n",
    "    \n",
    "    left_fitx, right_fitx, ploty = find_poly_values(left_fit, right_fit,\n",
    "                                                    binary_warped.shape)\n",
    "    new_left_fitx, new_right_fitx, ploty = find_poly_values(new_left_fit, new_right_fit,\n",
    "                                                            binary_warped.shape)\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    cv2.polylines(out_img,\n",
    "                  [np.array([new_left_fitx, ploty], dtype=np.int32).T],\n",
    "                  False,\n",
    "                  (255,255,0),\n",
    "                  thickness=2)\n",
    "    cv2.polylines(out_img,\n",
    "                  [np.array([new_right_fitx, ploty], dtype=np.int32).T],\n",
    "                  False,\n",
    "                  (255,255,0),\n",
    "                  thickness=2)\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "       \n",
    "    return ploty, new_left_fit, new_right_fit, new_left_fitx, new_right_fitx, result\n",
    "\n",
    "# Run image through the pipeline\n",
    "# Note that in your project, you'll also want to feed in the previous fits\n",
    "py, lf, rf, lfx, rfx, vis2 = search_around_poly(warped, lf, rf)\n",
    "\n",
    "# View your output\n",
    "# Plot the polynomial lines onto the image\n",
    "plt.figure(figsize=(15, 15))\n",
    "#plt.plot(lfx, py, color='yellow')\n",
    "#plt.plot(rfx, py, color='yellow')\n",
    "## End visualization steps ##\n",
    "plt.imshow(vis2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the curvature of the lane and vehicle position with respect to center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature_real(ploty, left_fitx, right_fitx):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in pixels.\n",
    "    '''    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "    \n",
    "    # Do the calculation of R_curve (radius of curvature) \n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    pos = (img_size[0]/2 - (left_fitx[-1] + right_fitx[-1])/2) * xm_per_pix\n",
    "    \n",
    "\n",
    "    return left_curverad, right_curverad, pos\n",
    "\n",
    "# Calculate the radius of curvature in meters for both lane lines\n",
    "left_curverad, right_curverad, pos = measure_curvature_real(py, lfx, rfx)\n",
    "print(left_curverad, 'm', right_curverad, 'm', pos, 'm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warp the detected lane boundaries back onto the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lane(undist, warped, left_fitx, right_fitx, ploty, M_inv):\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, M_inv, (G_W, G_H)) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def draw_text(img, l_curverad, r_curverad, relative_pos,\n",
    "              is_found = None, left_fit = None, right_fit = None):\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    cv2.putText(img,\n",
    "                'Left rad: ' + str(l_curverad) + ' (m)',\n",
    "                (50, 50), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(img,\n",
    "                'Right rad: ' + str(r_curverad) + ' (m)',\n",
    "                (50, 90), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(img,\n",
    "                'Position: ' + str(relative_pos) + ' (m)' ,\n",
    "                (50, 130), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    if left_fit is not None and right_fit is not None:\n",
    "        cv2.putText(img,\n",
    "                    'Found: ' + str(is_found),\n",
    "                    (50, 180), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)        \n",
    "        cv2.putText(img,\n",
    "                    'Left fit: ' + str(left_fit),\n",
    "                    (50, 220), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(img,\n",
    "                    'Right fit: ' + str(right_fit),\n",
    "                    (50, 260), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(img,\n",
    "                    'Diff: ' + str(right_fit - left_fit),\n",
    "                    (50, 300), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    return img\n",
    "\n",
    "result = draw_lane(undist, warped, lfx, rfx, py, m_inv)\n",
    "result = draw_text(result, left_curverad, right_curverad, pos, '-', lf, rf)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import IntEnum\n",
    "\n",
    "MAX_LOST_FRAMES = 5\n",
    "HISTORY_SIZE = 5\n",
    "\n",
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        self.detected = False  # was the line detected in the last iteration?\n",
    "        self.recent_xfitted = [] # x values of the last n fits of the line\n",
    "        self.recent_fit = [] # polynomial coefficients of the last n fits of the line\n",
    "        self.bestx = None #average x values of the fitted line over the last n iterations\n",
    "        self.best_fit = None #polynomial coefficients averaged over the last n iterations\n",
    "        self.current_fit = [np.array([False])] #polynomial coefficients for the most recent fit  \n",
    "        self.rad = None #radius of curvature of the line in some units\n",
    "        self.line_base_pos = None #distance in meters of vehicle center from the line\n",
    "        self.diffs = np.array([0,0,0], dtype='float') #difference in fit coefficients between last and new fits\n",
    "        self.allx = None #x values for detected line pixels\n",
    "        self.ally = None #y values for detected line pixels\n",
    "\n",
    "class State(IntEnum):\n",
    "    CLOSE_VIEW = 0\n",
    "    FAR_VIEW = 1\n",
    "        \n",
    "class ProcessSeq:\n",
    "    def __init__(self):\n",
    "        self.l_lane = Line()\n",
    "        self.r_lane = Line()\n",
    "        self.M = G_M\n",
    "        self.M_inv = G_M_inv\n",
    "        self.lost_frames = MAX_LOST_FRAMES\n",
    "        self.lane_pos = 0\n",
    "        self.corners = G_SRC_CORNERS\n",
    "        self.state = State.CLOSE_VIEW\n",
    "        self.top_persp_rect_edge_len = [200, 160]\n",
    "        self.history_len = 0\n",
    "    \n",
    "    def fit_dots(self, left_dots, right_dots):\n",
    "        leftx = left_dots[0].T[0]\n",
    "        lefty = left_dots[0].T[1]\n",
    "        rightx = right_dots[0].T[0]\n",
    "        righty = right_dots[0].T[1]\n",
    "\n",
    "        lf, rf = fit_poly(leftx, lefty, rightx, righty)\n",
    "        lfx, rfx, py = find_poly_values(lf, rf, G_SHAPE)\n",
    "        \n",
    "        return lf, rf, lfx, rfx\n",
    "    \n",
    "    def refit_lane(self, old_M, new_M, lfx, rfx):\n",
    "        # Convert back to top view\n",
    "        py = np.linspace(0, G_H - 1, G_H)\n",
    "        left_dots = cv2.perspectiveTransform(np.array([np.array([lfx, py], dtype=np.float32).T]), old_M_inv)\n",
    "        right_dots = cv2.perspectiveTransform(np.array([np.array([rfx, py], dtype=np.float32).T]), old_M_inv)\n",
    "\n",
    "        # Convert to perspective view with new perspective transform\n",
    "        left_dots_p = cv2.perspectiveTransform(left_dots, new_M)\n",
    "        right_dots_p = cv2.perspectiveTransform(right_dots, new_M)\n",
    "\n",
    "        return self.fit_dots(left_dots_p, right_dots_p)\n",
    "    \n",
    "    def update_history(self, old_M_inv, new_M):\n",
    "        for idx in range(self.history_len):\n",
    "            lf, rf, lfx, rfx = refit_lane(old_M_inv, new_M, self.l_lane.recent_xfitted[idx], self.r_lane.recent_xfitted[idx])\n",
    "            self.l_lane.recent_fit, self.r_lane.recent_fit = lf, rf\n",
    "            self.l_lane.recent_xfitted, self.r_lane.recent_xfitted = lfx, rfx\n",
    "            \n",
    "    def find_linear_lines(self, left_dots, right_dots):\n",
    "        left_x = np.array(left_dots[0].T[0])\n",
    "        left_y = np.array(left_dots[0].T[1])\n",
    "        right_x = np.array(right_dots[0].T[0])\n",
    "        right_y = np.array(right_dots[0].T[1])\n",
    "        \n",
    "        selected_left = ((left_x >=0) & (left_x <= G_W - 1) & (left_y >= 550))\n",
    "        selected_right = ((right_x >=0) & (right_x <= G_W - 1) & (right_y >= 550))\n",
    "        \n",
    "        ref_pts = RefPoints(460, X_MIDDLE)\n",
    "        l_line = find_line(left_x[selected_left], left_y[selected_left], ref_pts)\n",
    "        r_line = find_line(right_x[selected_right], right_y[selected_right], ref_pts)\n",
    "        return l_line, r_line\n",
    "        \n",
    "    def update_perspective(self, lf, rf, lfx, rfx, top_width):\n",
    "        # Translate lines coordinates to original image\n",
    "        py = np.linspace(0, G_H - 1, G_H)\n",
    "        left_dots = cv2.perspectiveTransform(np.array([np.array([lfx, py], dtype=np.float32).T]), self.M_inv)\n",
    "        right_dots = cv2.perspectiveTransform(np.array([np.array([rfx, py], dtype=np.float32).T]), self.M_inv)\n",
    "               \n",
    "        # Find linear lines approximation\n",
    "        l_line, r_line = self.find_linear_lines(left_dots, right_dots)\n",
    "        cv2.line(self.dbg, l_line[0], l_line[1], [255, 0, 0], 2)\n",
    "        cv2.line(self.dbg, r_line[0], r_line[1], [255, 0, 0], 2)\n",
    "\n",
    "        # Calculate new perspective matrix \n",
    "        new_M, new_M_inv, corners = calc_persp_matr(l_line, r_line, top_width)\n",
    "        \n",
    "        if new_M is not None:\n",
    "            # Update history (as previos fits became invalid)\n",
    "            self.update_history(self.M_inv, new_M)\n",
    "            \n",
    "            # Update current fit\n",
    "            left_dots_p = cv2.perspectiveTransform(left_dots, new_M)\n",
    "            right_dots_p = cv2.perspectiveTransform(right_dots, new_M)\n",
    "            lf, rf, lfx, rfx = self.fit_dots(left_dots_p, right_dots_p)\n",
    "\n",
    "            # Remember new perspective transform matrix\n",
    "            self.M = new_M\n",
    "            self.M_inv = new_M_inv\n",
    "            self.corners = corners\n",
    "    \n",
    "        return lf, rf, lfx, rfx \n",
    "        \n",
    "    def is_lane_found(self, left_fit, right_fit, left_fitx, right_fitx):\n",
    "        if left_fitx is None:\n",
    "            return False\n",
    "        \n",
    "        # If lane cuvature changed too agressively, detection is incorrect\n",
    "        if self.l_lane.current_fit[0]:\n",
    "            l_diff = abs(left_fit - self.l_lane.current_fit)\n",
    "            r_diff = abs(right_fit - self.r_lane.current_fit)\n",
    "            if (l_diff[0] > 5.0e-04 or r_diff[0] > 5.0e-04):\n",
    "                return False\n",
    "        \n",
    "        # If lanes have too different curvature, detection is incorrect\n",
    "        if (min(abs(left_fit[0]), abs(right_fit[0])) < 4.0e-04\n",
    "            and abs(left_fit[0] - right_fit[0]) > 12.0e-04):\n",
    "            return False\n",
    "        \n",
    "        if (abs(left_fit[0] - right_fit[0]) > 8.0e-04):\n",
    "            return False\n",
    "        \n",
    "        min_dist = 500\n",
    "        max_dist = 900\n",
    "        \n",
    "        # If distance between lines (in the bootom of image) is too big or too small,\n",
    "        # lane was detected incorrectly\n",
    "        dist_bot = abs(left_fitx[G_H-1] - right_fitx[G_H-1])\n",
    "        if (dist_bot < min_dist or dist_bot > max_dist):\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def is_sharp_turn(self, lf, rf, lfx, rfx):\n",
    "        if (abs(lf[0]) > 5.0e-04 or abs(rf[0]) > 5.0e-04\n",
    "            or np.any(lfx < 50)\n",
    "            or np.any(rfx > 1230)):            \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def reset_history(self):\n",
    "        del self.l_lane.recent_xfitted[:]\n",
    "        del self.r_lane.recent_xfitted[:]\n",
    "        del self.l_lane.recent_fit[:]\n",
    "        del self.r_lane.recent_fit[:]\n",
    "        self.history_len = 0\n",
    "        \n",
    "    def process_good_lane(self, lf, rf, py, lfx, rfx):        \n",
    "        if self.state == State.CLOSE_VIEW:\n",
    "            if (self.is_sharp_turn(lf, rf, lfx, rfx) or self.lost_frames >= MAX_LOST_FRAMES):\n",
    "                lf, rf, lfx, rfx = self.update_perspective(lf, rf, lfx, rfx,\n",
    "                                                           self.top_persp_rect_edge_len[self.state])\n",
    "            elif (self.history_len >= HISTORY_SIZE - 2\n",
    "                  and not self.is_sharp_turn(self.l_lane.best_fit, self.r_lane.best_fit,\n",
    "                                             self.l_lane.bestx, self.r_lane.bestx)):\n",
    "                self.state = State.FAR_VIEW\n",
    "                lf, rf, lfx, rfx = self.update_perspective(lf, rf, lfx, rfx,\n",
    "                                                           self.top_persp_rect_edge_len[self.state])\n",
    "        elif self.state == State.FAR_VIEW:\n",
    "            if (self.is_sharp_turn(lf, rf, lfx, rfx)\n",
    "                or self.lost_frames >= MAX_LOST_FRAMES):\n",
    "                self.state = State.CLOSE_VIEW\n",
    "                lf, rf, lfx, rfx = self.update_perspective(lf, rf, lfx, rfx,\n",
    "                                                           self.top_persp_rect_edge_len[self.state])\n",
    "        else:\n",
    "            raise ValueError('invalid state %r' % self.state)\n",
    "\n",
    "        # Calculate the radius of curvature in pixels for both lane lines\n",
    "        left_curverad, right_curverad, pos = measure_curvature_real(py, lfx, rfx)\n",
    "\n",
    "        self.l_lane.recent_xfitted.append(lfx)\n",
    "        self.r_lane.recent_xfitted.append(rfx)\n",
    "        self.l_lane.recent_fit.append(lf)\n",
    "        self.r_lane.recent_fit.append(rf)\n",
    "        self.history_len = len(self.l_lane.recent_xfitted)\n",
    "        if  self.history_len >= HISTORY_SIZE:\n",
    "            self.l_lane.recent_xfitted.pop(0)\n",
    "            self.r_lane.recent_xfitted.pop(0)\n",
    "            self.l_lane.recent_fit.pop(0)\n",
    "            self.r_lane.recent_fit.pop(0)\n",
    "\n",
    "        self.l_lane.bestx = np.mean(self.l_lane.recent_xfitted, axis=0)\n",
    "        self.r_lane.bestx = np.mean(self.r_lane.recent_xfitted, axis=0)\n",
    "        self.l_lane.best_fit = np.mean(self.l_lane.recent_fit, axis=0)\n",
    "        self.r_lane.best_fit = np.mean(self.r_lane.recent_fit, axis=0)\n",
    "\n",
    "        self.l_lane.rad = left_curverad\n",
    "        self.r_lane.rad = right_curverad\n",
    "        self.lane_pos = pos\n",
    "\n",
    "        self.l_lane.current_fit = lf\n",
    "        self.r_lane.current_fit = rf\n",
    "\n",
    "        self.l_lane.detected = True\n",
    "        self.r_lane.detected = True\n",
    "        self.lost_frames = 0\n",
    "\n",
    "        # Calculate the radius of curvature in pixels for both lane lines\n",
    "        left_curverad, right_curverad, pos = measure_curvature_real(py,\n",
    "                                                                    self.l_lane.bestx,\n",
    "                                                                    self.r_lane.bestx)\n",
    "        \n",
    "    def process_bad_lane(self):\n",
    "        self.l_lane.detected = False\n",
    "        self.r_lane.detected = False\n",
    "\n",
    "        if len(self.l_lane.recent_xfitted) > 0:\n",
    "            self.l_lane.recent_xfitted.pop(0)\n",
    "            self.r_lane.recent_xfitted.pop(0)\n",
    "            self.l_lane.recent_fit.pop(0)\n",
    "            self.r_lane.recent_fit.pop(0)\n",
    "            self.history_len -= 1\n",
    "\n",
    "        self.lost_frames += 1\n",
    "        if self.lost_frames >= MAX_LOST_FRAMES:\n",
    "            # Reset perspective transform matrix\n",
    "            self.M = G_M\n",
    "            self.M_inv = G_M_inv\n",
    "            self.corners = G_SRC_CORNERS\n",
    "            self.l_lane.current_fit = [np.array([False])]\n",
    "            self.r_lane.current_fit = [np.array([False])]\n",
    "            self.l_lane.bestx = None\n",
    "            self.r_lane.bestx = None\n",
    "            self.reset_history()\n",
    "\n",
    "    def __call__(self, img, dump_images = False, base = \"\", output_dir = \"\"):\n",
    "        # Undistort\n",
    "        undist = undistort(img)\n",
    "\n",
    "        # Make binary\n",
    "        bin_img, dbg_col_bin = make_binary(undist)\n",
    "        self.dbg = dbg_col_bin\n",
    "        \n",
    "        # Draw current perspective transform rectangle\n",
    "        cv2.polylines(dbg_col_bin,\n",
    "              [np.array(self.corners, dtype=np.int32).reshape((-1, 1, 2))],\n",
    "              True,\n",
    "              (255,255,0),\n",
    "              thickness=2)\n",
    "        \n",
    "        \n",
    "        # Perspective transform\n",
    "        warped_bin_img = perspective_transform(bin_img, self.M)\n",
    "            \n",
    "        # Find lanes and fit polynomial\n",
    "        ploty, lf, rf, lfx, rfx, vis = (None, None, None, None, None, None)\n",
    "        if self.lost_frames < MAX_LOST_FRAMES:\n",
    "            ploty, lf, rf, lfx, rfx, vis = search_around_poly(warped_bin_img,\n",
    "                                                              self.l_lane.current_fit,\n",
    "                                                              self.r_lane.current_fit)\n",
    "        else:\n",
    "            ploty, lf, rf, lfx, rfx, vis = fit_polynomial(warped_bin_img, DBG)\n",
    "        \n",
    "        #\n",
    "        # Process lanes info\n",
    "        #\n",
    "        is_found = self.is_lane_found(lf, rf, lfx, rfx)\n",
    "        if is_found:\n",
    "            self.process_good_lane(lf, rf, ploty, lfx, rfx)\n",
    "        else:\n",
    "            self.process_bad_lane()\n",
    "        \n",
    "        window_img = np.zeros_like(dbg_col_bin)\n",
    "        if  self.history_len >= 3:\n",
    "            cv2.polylines(window_img,\n",
    "                          [np.array([self.l_lane.recent_xfitted[-1], ploty], dtype=np.int32).T],\n",
    "                          False,\n",
    "                          (0,255,255),\n",
    "                          thickness=2)\n",
    "            cv2.polylines(window_img,\n",
    "                          [np.array([self.r_lane.recent_xfitted[-1], ploty], dtype=np.int32).T],\n",
    "                          False,\n",
    "                          (0,255,255),\n",
    "                          thickness=2)\n",
    "        vis = cv2.addWeighted(vis, 1, window_img, 0.3, 0)\n",
    "        \n",
    "        #\n",
    "        # Draw best approximation\n",
    "        #       \n",
    "        if self.history_len >= 2:\n",
    "            result = draw_lane(undist, warped, \n",
    "                               self.l_lane.bestx, self.r_lane.bestx,\n",
    "                               ploty, self.M_inv)\n",
    "        else:\n",
    "            result = undist\n",
    "            \n",
    "        result = self.draw_debug_info(result, lf, rf)\n",
    "        \n",
    "        if dump_images:\n",
    "            cv2.imwrite(output_dir + '/undist_' + base + '.jpg', undist)\n",
    "            cv2.imwrite(output_dir + '/bin_' + base + '.jpg', bin_img.astype('uint8') * 255)\n",
    "            cv2.imwrite(output_dir + '/warped_' + base + '.jpg', warped_bin_img.astype('uint8') * 255)\n",
    "\n",
    "\n",
    "        \n",
    "        #return dbg_col_bin\n",
    "        #vis[(warped_bin_img == 1)] = (255,255,255)\n",
    "        #return vis\n",
    "        #return np.dstack((warped_bin_img, warped_bin_img, warped_bin_img))*255\n",
    "        return np.concatenate((dbg_col_bin, vis, result), axis=1)\n",
    "    \n",
    "    def draw_debug_info(self, img, lf, rf):\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(img, 'Left rad: ' + str(self.l_lane.rad) + ' (m)',\n",
    "                    (50, 50), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(img, 'Right rad: ' + str(self.r_lane.rad) + ' (m)',\n",
    "                    (50, 90), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(img, 'Position: ' + str(self.lane_pos) + ' (m)' ,\n",
    "                    (50, 130), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(img, 'Found: ' + str(self.l_lane.detected and self.r_lane.detected),\n",
    "                    (50, 180), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(img, 'History len: ' + str(self.history_len),\n",
    "                    (250, 180), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(img, 'Frames lost: ' + str(self.lost_frames),\n",
    "                    (450, 180), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA) \n",
    "        cv2.putText(img, 'Left fit: ' + str(lf),\n",
    "                    (50, 220), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(img, 'Right fit: ' + str(rf),\n",
    "                    (50, 260), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(img, 'Diff: ' + str(lf - rf),\n",
    "                    (50, 300), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "        return img\n",
    "\n",
    "# Make a list of images\n",
    "images = glob.glob('test_images/*.jpg') + glob.glob('dbg/*.jpg')\n",
    "images_count = len(images)\n",
    "fig, ax = plt.subplots(int((images_count + 1) / 2), 2, figsize=(10, 25))\n",
    "\n",
    "# Step through the list\n",
    "for idx, fname in enumerate(images):\n",
    "    t_img = cv2.imread(fname)\n",
    "    t_img = cv2.cvtColor(t_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Get base name\n",
    "    base = os.path.basename(fname)\n",
    "    base = os.path.splitext(base)[0]\n",
    "    \n",
    "    process_img = ProcessSeq()\n",
    "    result = process_img(t_img, DBG, base, 'output_images')\n",
    "    \n",
    "    cv2.imwrite('output_images/res_' + base + '.jpg',\n",
    "                cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # plot original and final image\n",
    "    row = int(idx / 2)\n",
    "    col = idx % 2\n",
    "    ax[row, col].set_title(fname, fontsize=15)\n",
    "    ax[row, col].imshow(result)\n",
    "    \n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [(450, 700),\n",
    "          (0, 480),\n",
    "          (0, 1260)]\n",
    "\n",
    "dump_range = [0, 1260]\n",
    "\n",
    "for vid, name in enumerate(clip_names):\n",
    "    process_img = ProcessSeq()\n",
    "    clip1 = VideoFileClip(name)\n",
    "\n",
    "    if vid == 2:\n",
    "        for idx, frame in enumerate(log_progress(clip1.iter_frames(), every=1)):\n",
    "            if idx >= ranges[vid][0] and idx < max(ranges[vid][1], dump_range[1]):\n",
    "                #result = detect_lines(frame)\n",
    "                result = process_img(frame)\n",
    "                \n",
    "                if idx >= dump_range[0] and idx < dump_range[1]:\n",
    "                    cv2.imwrite('output_dbg/vid' + str(vid) + '_dbg_' + str(idx) + '.jpg',\n",
    "                                cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "    clip1.close()\n",
    "\n",
    "frame_num = -1\n",
    "if frame_num >= 0:\n",
    "    frame = clip1.get_frame(float(frame_num)/clip1.fps)\n",
    "    cv2.imwrite('output_dbg/vid3_frame_' + str(frame_num) + '.jpg',\n",
    "                cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    result = process_img(frame)\n",
    "    cv2.imwrite('output_dbg/vid3_frame_' + str(frame_num) + '_out.jpg',\n",
    "                cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    clip1.close()\n",
    "#white_clip = clip1.fl_image(process_img) #NOTE: this function expects color images!!\n",
    "#%time white_clip.write_videofile('output_videos/project_video_out.mp4', audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(ProcessSeq()) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile('output_videos/project_video_out.mp4', audio=False)\n",
    "clip1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(ProcessSeq()) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile('output_videos/challenge_video_out.mp4', audio=False)\n",
    "clip1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(ProcessSeq()) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile('output_videos/harder_challenge_video_out.mp4', audio=False)\n",
    "clip1.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "0296ff19162e43d08371d56979f18ecb": {
     "views": []
    },
    "05c146a0b4aa4462984d3f20989b4428": {
     "views": []
    },
    "084daa75e1b34b1e96ce43253b48e888": {
     "views": []
    },
    "08a2bbf3e3114584b83e3d8a86aea041": {
     "views": []
    },
    "12cf91a3f12643aca76b51da6f5d5217": {
     "views": []
    },
    "2336cb694d50434dbf3e076a968bccd9": {
     "views": []
    },
    "244761188d4e44df8de7a3f9fc6fbd0c": {
     "views": []
    },
    "245e156678a646589e3fa5dfa0f3d25f": {
     "views": []
    },
    "29763cec888a4de3b75ca07191001493": {
     "views": []
    },
    "3cf2233c31074e53be3942a945af3206": {
     "views": []
    },
    "3dff05c3f8b944e086825f9fde597b6c": {
     "views": []
    },
    "460178100dd4437e9ff2fdd56873d9a9": {
     "views": []
    },
    "4b3754ac982f4a9b97cda2d550c6910b": {
     "views": []
    },
    "569d8486beb14fb681e8a40dce7ae26c": {
     "views": []
    },
    "57c0062320ea46c08365b6bef43bd087": {
     "views": []
    },
    "5dd0d954511d4a418b92b2a5ee8e9ada": {
     "views": []
    },
    "637b3dc283124a00b5ab5ed1b5f30f92": {
     "views": []
    },
    "6bfbf347054a450ba5e68fdcf0fd0bfb": {
     "views": []
    },
    "6c6c906ac61247e0b8295d2e51265a96": {
     "views": []
    },
    "6d49f90fa4b0425cbf02610a75100987": {
     "views": []
    },
    "76f2b901ee9d4fa89cef30f0a22b3baa": {
     "views": []
    },
    "77b9a13efd8142e2b17f246dd1246b8f": {
     "views": []
    },
    "791386682f7840e5867bdbd937423875": {
     "views": []
    },
    "7db9b8a926d34d32bf9dd763fe635bbd": {
     "views": []
    },
    "82dca5f60bbc4df0b3d4c0428bf39eaa": {
     "views": []
    },
    "855f38330ec942c5b7cf5b2463a45552": {
     "views": []
    },
    "85e3ea2450034aef910103d12b46003c": {
     "views": []
    },
    "91ad7564802b4741b1c7b00dacc2961d": {
     "views": []
    },
    "97892d93b7874c7c942207051e7fee67": {
     "views": []
    },
    "9d1c80ca2f3f4b3e813b367cae9c4e8b": {
     "views": []
    },
    "a65e5db0358b431a884dd9427cbfb7a0": {
     "views": []
    },
    "a719f4b0db69416bb6302c4fd96631fc": {
     "views": []
    },
    "aa09565d7d5940cbb6907453e407a5a9": {
     "views": []
    },
    "acdcca475b8347e8a74e20ecac071544": {
     "views": []
    },
    "b3827873b5094349b98930fb74684b6d": {
     "views": []
    },
    "ba16f0c22f6d43f7a818b16977ac94c0": {
     "views": []
    },
    "bb550ddd3de54136bfe19d85aeb81b32": {
     "views": []
    },
    "bda9562eace04e99a7cebf047f120eb9": {
     "views": []
    },
    "c08365af5d3e410f8d126a5e8ebf6f7d": {
     "views": []
    },
    "c52a9dd20ba141df921c10bef0e9bf32": {
     "views": []
    },
    "c61b4cf8a47a462e9fc98a85ec946290": {
     "views": []
    },
    "cafc87a1900245e8947da68ef03ed816": {
     "views": []
    },
    "cc0ee6b87ce3442c9ae01f772b621da1": {
     "views": []
    },
    "e4e69789ea804d2e99def286c7445521": {
     "views": []
    },
    "e892a4245c9a411faabc1cbc2539d1a1": {
     "views": []
    },
    "f6b533dff27c4bef9d2a456ebaa62441": {
     "views": []
    },
    "f8d5655c67af410392603f6897e60bca": {
     "views": []
    },
    "f9f25d5288be46a1ba47a1dbf0c7e54e": {
     "views": []
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
